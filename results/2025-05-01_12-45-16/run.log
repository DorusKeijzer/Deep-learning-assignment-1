Training models:
	most recent baseline:
	  <bound method Module.parameters of MostRecentBaseline()>
	Mean Baseline:
	  <bound method Module.parameters of MeanBaseline()>
	GRU:
	  <bound method Module.parameters of GRUModel(
  (gru): GRU(1, 64, batch_first=True)
  (fc): Linear(in_features=64, out_features=1, bias=True)
)>
	GRU:
	  <bound method Module.parameters of GRUModel(
  (gru): GRU(1, 64, num_layers=2, batch_first=True)
  (fc): Linear(in_features=64, out_features=1, bias=True)
)>
	GRU:
	  <bound method Module.parameters of GRUModel(
  (gru): GRU(1, 64, num_layers=3, batch_first=True)
  (fc): Linear(in_features=64, out_features=1, bias=True)
)>
	GRU:
	  <bound method Module.parameters of GRUModel(
  (gru): GRU(1, 64, num_layers=4, batch_first=True)
  (fc): Linear(in_features=64, out_features=1, bias=True)
)>
	1D CNN:
	  <bound method Module.parameters of CNN1DModel(
  (cnn): Sequential(
    (0): Sequential(
      (conv_0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (bn_0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu_0): ReLU()
      (dropout_0): Dropout(p=0.2, inplace=False)
      (adapool_0): AdaptiveAvgPool1d(output_size=1)
    )
    (1): Sequential(
      (conv_1): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (bn_1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu_1): ReLU()
      (dropout_1): Dropout(p=0.2, inplace=False)
      (adapool_1): AdaptiveAvgPool1d(output_size=1)
    )
  )
  (fc): LazyLinear(in_features=0, out_features=1, bias=True)
)>
Using lag parameters: 5
On datasets: Padding, Non-padding
For 100 epochs, with early stopping.
Training and evaluating model: most recent baseline  on dataset: Padding
/home/dorus/Documenten/UU/Blok 4/deep_learning/Deep-learning-assignment-1/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/dorus/Documenten/UU/Blok 4/deep_learning/Deep-learning-assignment-1/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
Root MSE: 76.276705
Training and evaluating model: most recent baseline  on dataset: Non-padding
Root MSE: 72.645237
Training and evaluating model: Mean Baseline  on dataset: Padding
Root MSE: 76.276705
Training and evaluating model: Mean Baseline  on dataset: Non-padding
Root MSE: 72.645237
Training and evaluating model: GRU hidden dimensions: 64, number of layers: 1 on dataset: Padding

Epoch 1/100
-------------------------------
/home/dorus/Documenten/UU/Blok 4/deep_learning/Deep-learning-assignment-1/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
loss: 5672.903320 [   32/  800]
loss: 5472.973551 [  192/  800]
loss: 5163.215066 [  352/  800]
loss: 5693.287628 [  512/  800]
loss: 5829.655018 [  672/  800]
Epoch complete - average loss: 5718.934639
/home/dorus/Documenten/UU/Blok 4/deep_learning/Deep-learning-assignment-1/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
Root MSE: 74.927080

Epoch 2/100
-------------------------------
loss: 4410.779297 [   32/  800]
loss: 5075.864502 [  192/  800]
loss: 5088.278520 [  352/  800]
loss: 5499.324509 [  512/  800]
loss: 5407.351714 [  672/  800]
Epoch complete - average loss: 5486.306729
Root MSE: 73.474892

Epoch 3/100
-------------------------------
loss: 6715.591797 [   32/  800]
loss: 5504.963867 [  192/  800]
loss: 5970.006525 [  352/  800]
loss: 5914.783875 [  512/  800]
loss: 5428.939290 [  672/  800]
Epoch complete - average loss: 5270.387949
Root MSE: 71.972073

Epoch 4/100
-------------------------------
loss: 5997.468262 [   32/  800]
loss: 5872.626953 [  192/  800]
loss: 4723.689375 [  352/  800]
loss: 5095.804359 [  512/  800]
loss: 5105.533965 [  672/  800]
Epoch complete - average loss: 5040.245337
Root MSE: 70.435952

Epoch 5/100
-------------------------------
loss: 6055.482422 [   32/  800]
loss: 4813.845622 [  192/  800]
loss: 4618.206321 [  352/  800]
loss: 4801.408020 [  512/  800]
loss: 4820.768497 [  672/  800]
Epoch complete - average loss: 4832.321377
Root MSE: 69.108846

Epoch 6/100
-------------------------------
loss: 5220.242188 [   32/  800]
loss: 4522.764933 [  192/  800]
loss: 4972.731934 [  352/  800]
loss: 4797.205536 [  512/  800]
loss: 4739.849330 [  672/  800]
Epoch complete - average loss: 4658.687480
Root MSE: 67.930719

Epoch 7/100
-------------------------------
loss: 6512.958496 [   32/  800]
loss: 5037.694417 [  192/  800]
loss: 5082.899503 [  352/  800]
loss: 4721.568298 [  512/  800]
loss: 4495.527646 [  672/  800]
Epoch complete - average loss: 4500.910937
Root MSE: 66.807432

Epoch 8/100
-------------------------------
loss: 5630.983887 [   32/  800]
loss: 4229.071655 [  192/  800]
loss: 4052.542014 [  352/  800]
loss: 4419.905869 [  512/  800]
loss: 4258.791516 [  672/  800]
Epoch complete - average loss: 4346.244531
Root MSE: 65.669799

Epoch 9/100
-------------------------------
loss: 5210.906250 [   32/  800]
loss: 4283.772705 [  192/  800]
loss: 4007.404119 [  352/  800]
loss: 4438.980408 [  512/  800]
loss: 4266.110491 [  672/  800]
Epoch complete - average loss: 4190.859941
Root MSE: 64.498442

Epoch 10/100
-------------------------------
loss: 5317.173340 [   32/  800]
loss: 4260.217977 [  192/  800]
loss: 3959.106357 [  352/  800]
loss: 4236.345154 [  512/  800]
loss: 4055.317871 [  672/  800]
Epoch complete - average loss: 4045.580010
Root MSE: 63.446284

Epoch 11/100
-------------------------------
loss: 2172.378418 [   32/  800]
loss: 4192.210856 [  192/  800]
loss: 4174.728582 [  352/  800]
loss: 4058.525406 [  512/  800]
loss: 3936.057175 [  672/  800]
Epoch complete - average loss: 3911.884668
Root MSE: 62.416838

Epoch 12/100
-------------------------------
loss: 2730.405518 [   32/  800]
loss: 3549.341654 [  192/  800]
loss: 3511.637285 [  352/  800]
loss: 3565.436295 [  512/  800]
loss: 3908.559954 [  672/  800]
Epoch complete - average loss: 3779.331855
Root MSE: 61.360697

Epoch 13/100
-------------------------------
loss: 4583.930176 [   32/  800]
loss: 4321.763509 [  192/  800]
loss: 3856.161355 [  352/  800]
loss: 3609.602776 [  512/  800]
loss: 3607.282232 [  672/  800]
Epoch complete - average loss: 3651.640396
Root MSE: 60.391156

Epoch 14/100
-------------------------------
loss: 3597.902832 [   32/  800]
loss: 3500.830566 [  192/  800]
loss: 3695.436679 [  352/  800]
loss: 3603.662140 [  512/  800]
loss: 3694.413528 [  672/  800]
Epoch complete - average loss: 3535.333926
Root MSE: 59.454634

Epoch 15/100
-------------------------------
loss: 4226.560059 [   32/  800]
loss: 3791.589966 [  192/  800]
loss: 3574.414484 [  352/  800]
loss: 3480.519043 [  512/  800]
loss: 3474.468215 [  672/  800]
Epoch complete - average loss: 3421.197739
Root MSE: 58.511570

Epoch 16/100
-------------------------------
loss: 1358.379028 [   32/  800]
loss: 2737.070496 [  192/  800]
loss: 3079.611073 [  352/  800]
loss: 3361.444908 [  512/  800]
loss: 3302.781907 [  672/  800]
Epoch complete - average loss: 3311.845244
Root MSE: 57.681174

Epoch 17/100
-------------------------------
loss: 3217.105713 [   32/  800]
loss: 2839.149414 [  192/  800]
loss: 3462.508634 [  352/  800]
loss: 3253.140137 [  512/  800]
loss: 3209.026449 [  672/  800]
Epoch complete - average loss: 3218.458389
Root MSE: 56.897561

Epoch 18/100
-------------------------------
loss: 3061.156006 [   32/  800]
loss: 3654.225382 [  192/  800]
loss: 3438.335716 [  352/  800]
loss: 3312.996941 [  512/  800]
loss: 3124.113432 [  672/  800]
Epoch complete - average loss: 3132.008271
Root MSE: 56.178812

Epoch 19/100
-------------------------------
loss: 2876.413818 [   32/  800]
loss: 2825.009460 [  192/  800]
loss: 3013.206243 [  352/  800]
loss: 3025.071968 [  512/  800]
loss: 3065.364194 [  672/  800]
Epoch complete - average loss: 3051.561968
Root MSE: 55.526652

Epoch 20/100
-------------------------------
loss: 2237.142334 [   32/  800]
loss: 2878.707275 [  192/  800]
loss: 2646.845503 [  352/  800]
loss: 2870.369446 [  512/  800]
loss: 2979.178519 [  672/  800]
Epoch complete - average loss: 2978.878218
Root MSE: 54.912946

Epoch 21/100
-------------------------------
loss: 5333.535645 [   32/  800]
loss: 3875.615194 [  192/  800]
loss: 3664.900657 [  352/  800]
loss: 3110.164692 [  512/  800]
loss: 3105.713591 [  672/  800]
Epoch complete - average loss: 2913.406582
Root MSE: 54.306983

Epoch 22/100
-------------------------------
loss: 1003.643982 [   32/  800]
loss: 3213.354075 [  192/  800]
loss: 2711.216270 [  352/  800]
loss: 2879.468807 [  512/  800]
loss: 2867.161577 [  672/  800]
Epoch complete - average loss: 2848.380881
Root MSE: 53.792289

Epoch 23/100
-------------------------------
loss: 3147.229736 [   32/  800]
loss: 2473.977051 [  192/  800]
loss: 2568.401412 [  352/  800]
loss: 2772.416946 [  512/  800]
loss: 2820.462635 [  672/  800]
Epoch complete - average loss: 2790.693110
Root MSE: 53.296291

Epoch 24/100
-------------------------------
loss: 2909.885986 [   32/  800]
loss: 3158.125997 [  192/  800]
loss: 2611.253673 [  352/  800]
loss: 2525.703072 [  512/  800]
loss: 2766.974673 [  672/  800]
Epoch complete - average loss: 2737.794116
Root MSE: 52.827192

Epoch 25/100
-------------------------------
loss: 5038.728516 [   32/  800]
loss: 3109.744731 [  192/  800]
loss: 2771.586570 [  352/  800]
loss: 2715.359001 [  512/  800]
loss: 2710.362880 [  672/  800]
Epoch complete - average loss: 2689.596450
Root MSE: 52.385027

Epoch 26/100
-------------------------------
loss: 1516.170288 [   32/  800]
loss: 2798.622253 [  192/  800]
loss: 2629.150013 [  352/  800]
loss: 2575.669388 [  512/  800]
loss: 2575.148600 [  672/  800]
Epoch complete - average loss: 2640.468984
Root MSE: 51.989667

Epoch 27/100
-------------------------------
loss: 2802.994629 [   32/  800]
loss: 3042.313354 [  192/  800]
loss: 2788.482733 [  352/  800]
loss: 2858.723083 [  512/  800]
loss: 2636.139462 [  672/  800]
Epoch complete - average loss: 2600.949614
Root MSE: 51.596024

Epoch 28/100
-------------------------------
loss: 2616.245605 [   32/  800]
loss: 2480.732422 [  192/  800]
loss: 2475.257779 [  352/  800]
loss: 2534.590485 [  512/  800]
loss: 2610.983916 [  672/  800]
Epoch complete - average loss: 2559.876323
Root MSE: 51.258839

Epoch 29/100
-------------------------------
loss: 3205.335938 [   32/  800]
loss: 2563.886698 [  192/  800]
loss: 2385.772195 [  352/  800]
loss: 2491.899170 [  512/  800]
loss: 2531.898624 [  672/  800]
Epoch complete - average loss: 2524.965503
Root MSE: 50.945037

Epoch 30/100
-------------------------------
loss: 3313.878174 [   32/  800]
loss: 2580.606283 [  192/  800]
loss: 2394.204024 [  352/  800]
loss: 2326.051712 [  512/  800]
loss: 2482.144973 [  672/  800]
Epoch complete - average loss: 2491.824844
Root MSE: 50.640525

Epoch 31/100
-------------------------------
loss: 2404.502930 [   32/  800]
loss: 2428.044230 [  192/  800]
loss: 2650.744451 [  352/  800]
loss: 2578.005310 [  512/  800]
loss: 2472.353620 [  672/  800]
Epoch complete - average loss: 2462.287412
Root MSE: 50.361828

Epoch 32/100
-------------------------------
loss: 1896.020752 [   32/  800]
loss: 2303.624451 [  192/  800]
loss: 2478.292336 [  352/  800]
loss: 2437.533096 [  512/  800]
loss: 2381.806472 [  672/  800]
Epoch complete - average loss: 2434.332397
Root MSE: 50.111312

Epoch 33/100
-------------------------------
loss: 1302.678223 [   32/  800]
loss: 2243.124390 [  192/  800]
loss: 2525.636486 [  352/  800]
loss: 2504.173050 [  512/  800]
loss: 2579.449289 [  672/  800]
Epoch complete - average loss: 2408.644878
Root MSE: 49.881527

Epoch 34/100
-------------------------------
loss: 2020.414673 [   32/  800]
loss: 2573.877502 [  192/  800]
loss: 2515.169278 [  352/  800]
loss: 2536.992737 [  512/  800]
loss: 2417.937279 [  672/  800]
Epoch complete - average loss: 2385.528643
Root MSE: 49.670182

Epoch 35/100
-------------------------------
loss: 2772.215332 [   32/  800]
loss: 2477.619853 [  192/  800]
loss: 2226.682340 [  352/  800]
loss: 2238.684532 [  512/  800]
loss: 2356.553194 [  672/  800]
Epoch complete - average loss: 2363.255063
Root MSE: 49.482477

Epoch 36/100
-------------------------------
loss: 1542.135620 [   32/  800]
loss: 1930.313700 [  192/  800]
loss: 1876.238803 [  352/  800]
loss: 1981.743851 [  512/  800]
loss: 2272.984433 [  672/  800]
Epoch complete - average loss: 2344.594282
Root MSE: 49.316576

Epoch 37/100
-------------------------------
loss: 2697.757812 [   32/  800]
loss: 2016.487254 [  192/  800]
loss: 2260.183056 [  352/  800]
loss: 2257.800991 [  512/  800]
loss: 2393.325675 [  672/  800]
Epoch complete - average loss: 2327.173499
Root MSE: 49.148375

Epoch 38/100
-------------------------------
loss: 1586.830811 [   32/  800]
loss: 2336.774333 [  192/  800]
loss: 2429.242143 [  352/  800]
loss: 2176.710274 [  512/  800]
loss: 2324.572707 [  672/  800]
Epoch complete - average loss: 2311.405830
Root MSE: 49.002374

Epoch 39/100
-------------------------------
loss: 1975.494141 [   32/  800]
loss: 2894.916260 [  192/  800]
loss: 2745.647483 [  352/  800]
loss: 2510.908554 [  512/  800]
loss: 2371.221930 [  672/  800]
Epoch complete - average loss: 2297.677056
Root MSE: 48.857997

Epoch 40/100
-------------------------------
loss: 1772.277344 [   32/  800]
loss: 2078.196289 [  192/  800]
loss: 2178.493913 [  352/  800]
loss: 2173.210690 [  512/  800]
loss: 2132.220308 [  672/  800]
Epoch complete - average loss: 2282.160313
Root MSE: 48.757309

Epoch 41/100
-------------------------------
loss: 1701.180298 [   32/  800]
loss: 2205.786682 [  192/  800]
loss: 2065.975453 [  352/  800]
loss: 2134.066002 [  512/  800]
loss: 2068.973075 [  672/  800]
Epoch complete - average loss: 2270.533750
Root MSE: 48.648268

Epoch 42/100
-------------------------------
loss: 2535.022217 [   32/  800]
loss: 2252.704142 [  192/  800]
loss: 2485.054044 [  352/  800]
loss: 2360.694359 [  512/  800]
loss: 2252.642677 [  672/  800]
Epoch complete - average loss: 2260.418076
Root MSE: 48.543322

Epoch 43/100
-------------------------------
loss: 2515.510498 [   32/  800]
loss: 1884.727549 [  192/  800]
loss: 2150.468056 [  352/  800]
loss: 2149.480503 [  512/  800]
loss: 2208.910613 [  672/  800]
Epoch complete - average loss: 2249.508577
Root MSE: 48.464031

Epoch 44/100
-------------------------------
loss: 2222.959229 [   32/  800]
loss: 2089.036865 [  192/  800]
loss: 2143.764915 [  352/  800]
loss: 2077.950829 [  512/  800]
loss: 2136.196190 [  672/  800]
Epoch complete - average loss: 2241.706816
Root MSE: 48.381062

Epoch 45/100
-------------------------------
loss: 1400.794556 [   32/  800]
loss: 2273.765401 [  192/  800]
loss: 2265.604048 [  352/  800]
loss: 2436.065430 [  512/  800]
loss: 2326.315746 [  672/  800]
Epoch complete - average loss: 2233.084773
Root MSE: 48.296842

Epoch 46/100
-------------------------------
loss: 1775.322021 [   32/  800]
loss: 2359.314677 [  192/  800]
loss: 2171.960671 [  352/  800]
loss: 2166.682167 [  512/  800]
loss: 2095.911051 [  672/  800]
Epoch complete - average loss: 2224.416689
Root MSE: 48.247485

Epoch 47/100
-------------------------------
loss: 4301.775391 [   32/  800]
loss: 3021.558736 [  192/  800]
loss: 2518.663042 [  352/  800]
loss: 2453.234627 [  512/  800]
loss: 2290.838774 [  672/  800]
Epoch complete - average loss: 2219.672275
Root MSE: 48.179498

Epoch 48/100
-------------------------------
loss: 1561.992432 [   32/  800]
loss: 2033.902649 [  192/  800]
loss: 2119.440396 [  352/  800]
loss: 2223.612740 [  512/  800]
loss: 2182.436250 [  672/  800]
Epoch complete - average loss: 2212.650356
Root MSE: 48.139154

Epoch 49/100
-------------------------------
loss: 1774.437256 [   32/  800]
loss: 2219.327169 [  192/  800]
loss: 2314.742698 [  352/  800]
loss: 2194.720459 [  512/  800]
loss: 2160.907308 [  672/  800]
Epoch complete - average loss: 2208.337915
Root MSE: 48.096034

Epoch 50/100
-------------------------------
loss: 2278.340088 [   32/  800]
loss: 2200.022156 [  192/  800]
loss: 2224.266169 [  352/  800]
loss: 2213.917511 [  512/  800]
loss: 2157.679653 [  672/  800]
Epoch complete - average loss: 2202.146982
Root MSE: 48.059373

Epoch 51/100
-------------------------------
loss: 2542.774902 [   32/  800]
loss: 2165.477458 [  192/  800]
loss: 2347.295033 [  352/  800]
loss: 2421.438080 [  512/  800]
loss: 2275.741693 [  672/  800]
Epoch complete - average loss: 2199.397148
Root MSE: 48.026443

Epoch 52/100
-------------------------------
loss: 1657.128418 [   32/  800]
loss: 2823.896159 [  192/  800]
loss: 2517.555842 [  352/  800]
loss: 2263.504459 [  512/  800]
loss: 2178.839504 [  672/  800]
Epoch complete - average loss: 2196.630442
Root MSE: 47.995467

Epoch 53/100
-------------------------------
loss: 1423.857544 [   32/  800]
loss: 2492.192627 [  192/  800]
loss: 2175.733454 [  352/  800]
loss: 2140.218124 [  512/  800]
loss: 2161.555682 [  672/  800]
Epoch complete - average loss: 2192.987441
Root MSE: 47.976467

Epoch 54/100
-------------------------------
loss: 2550.238281 [   32/  800]
loss: 1992.246348 [  192/  800]
loss: 1941.550609 [  352/  800]
loss: 2173.254337 [  512/  800]
loss: 2221.753752 [  672/  800]
Epoch complete - average loss: 2191.448386
Root MSE: 47.959814

Epoch 55/100
-------------------------------
loss: 1081.297119 [   32/  800]
loss: 1818.712280 [  192/  800]
loss: 1744.770053 [  352/  800]
loss: 2023.918610 [  512/  800]
loss: 2135.511765 [  672/  800]
Epoch complete - average loss: 2188.371299
Root MSE: 47.944319

Epoch 56/100
-------------------------------
loss: 1527.229492 [   32/  800]
loss: 2122.645874 [  192/  800]
loss: 2144.636064 [  352/  800]
loss: 2270.309196 [  512/  800]
loss: 2231.087943 [  672/  800]
Epoch complete - average loss: 2186.378462
Root MSE: 47.926235

Epoch 57/100
-------------------------------
loss: 2470.041748 [   32/  800]
loss: 2065.265584 [  192/  800]
loss: 2283.611661 [  352/  800]
loss: 2127.011749 [  512/  800]
loss: 2173.554339 [  672/  800]
Epoch complete - average loss: 2185.002368
Root MSE: 47.914009

Epoch 58/100
-------------------------------
loss: 1988.825684 [   32/  800]
loss: 2130.985718 [  192/  800]
loss: 2255.405063 [  352/  800]
loss: 2207.849449 [  512/  800]
loss: 2246.204479 [  672/  800]
Epoch complete - average loss: 2183.488921
Root MSE: 47.903535

Epoch 59/100
-------------------------------
loss: 1705.002075 [   32/  800]
loss: 2126.884033 [  192/  800]
loss: 2139.559304 [  352/  800]
loss: 2183.607986 [  512/  800]
loss: 2201.090390 [  672/  800]
Epoch complete - average loss: 2181.306865
Root MSE: 47.895615

Epoch 60/100
-------------------------------
loss: 1927.374512 [   32/  800]
loss: 2295.830444 [  192/  800]
loss: 2423.289462 [  352/  800]
loss: 2363.762314 [  512/  800]
loss: 2288.222616 [  672/  800]
Epoch complete - average loss: 2181.417573
Root MSE: 47.885563

Epoch 61/100
-------------------------------
loss: 2751.223145 [   32/  800]
loss: 2142.709106 [  192/  800]
loss: 2423.932151 [  352/  800]
loss: 2325.665070 [  512/  800]
loss: 2260.346656 [  672/  800]
Epoch complete - average loss: 2180.853418
Root MSE: 47.882042

Epoch 62/100
-------------------------------
loss: 1961.591309 [   32/  800]
loss: 2230.662842 [  192/  800]
loss: 2285.295743 [  352/  800]
loss: 2326.931030 [  512/  800]
loss: 2213.366722 [  672/  800]
Epoch complete - average loss: 2179.025083
Root MSE: 47.877365

Epoch 63/100
-------------------------------
loss: 1864.198242 [   32/  800]
loss: 1909.878479 [  192/  800]
loss: 2111.333973 [  352/  800]
loss: 2024.555618 [  512/  800]
loss: 2122.558960 [  672/  800]
Epoch complete - average loss: 2178.338496
Root MSE: 47.874574

Epoch 64/100
-------------------------------
loss: 2195.175293 [   32/  800]
loss: 2240.902995 [  192/  800]
loss: 2151.127752 [  352/  800]
loss: 2182.184967 [  512/  800]
loss: 2258.930827 [  672/  800]
Epoch complete - average loss: 2177.717939
Root MSE: 47.870773

Epoch 65/100
-------------------------------
loss: 1659.561035 [   32/  800]
loss: 2220.819722 [  192/  800]
loss: 2215.438399 [  352/  800]
loss: 2139.308380 [  512/  800]
loss: 2218.713112 [  672/  800]
Epoch complete - average loss: 2176.349443
Root MSE: 47.868331

Epoch 66/100
-------------------------------
loss: 1400.985596 [   32/  800]
loss: 1966.617086 [  192/  800]
loss: 2289.836737 [  352/  800]
loss: 2204.229355 [  512/  800]
loss: 2308.030675 [  672/  800]
Epoch complete - average loss: 2179.123511
Root MSE: 47.865762

Epoch 67/100
-------------------------------
loss: 2198.374512 [   32/  800]
loss: 2214.770447 [  192/  800]
loss: 2315.774015 [  352/  800]
loss: 2288.445648 [  512/  800]
loss: 2250.147725 [  672/  800]
Epoch complete - average loss: 2177.011711
Root MSE: 47.864666

Epoch 68/100
-------------------------------
loss: 1443.929932 [   32/  800]
loss: 1970.832642 [  192/  800]
loss: 1972.166870 [  352/  800]
loss: 2105.932304 [  512/  800]
loss: 2127.865775 [  672/  800]
Epoch complete - average loss: 2175.393647
Root MSE: 47.864245

Epoch 69/100
-------------------------------
loss: 2015.816772 [   32/  800]
loss: 2053.534892 [  192/  800]
loss: 2152.064220 [  352/  800]
loss: 2085.528275 [  512/  800]
loss: 2179.786819 [  672/  800]
Epoch complete - average loss: 2175.104541
Root MSE: 47.863439

Epoch 70/100
-------------------------------
loss: 1610.601685 [   32/  800]
loss: 2114.742289 [  192/  800]
loss: 2139.041903 [  352/  800]
loss: 2125.748711 [  512/  800]
loss: 2115.270368 [  672/  800]
Epoch complete - average loss: 2174.945596
Root MSE: 47.862866

Epoch 71/100
-------------------------------
loss: 2046.809570 [   32/  800]
loss: 2102.053385 [  192/  800]
loss: 2148.861606 [  352/  800]
loss: 2131.608055 [  512/  800]
loss: 2172.436093 [  672/  800]
Epoch complete - average loss: 2174.905049
Root MSE: 47.862615

Epoch 72/100
-------------------------------
loss: 1755.002686 [   32/  800]
loss: 2159.543925 [  192/  800]
loss: 2324.943859 [  352/  800]
loss: 2272.171898 [  512/  800]
loss: 2184.909825 [  672/  800]
Epoch complete - average loss: 2174.647764
Root MSE: 47.862641

Epoch 73/100
-------------------------------
loss: 1663.205811 [   32/  800]
loss: 1960.451874 [  192/  800]
loss: 1994.306380 [  352/  800]
loss: 2095.460712 [  512/  800]
loss: 2122.941816 [  672/  800]
Epoch complete - average loss: 2175.200349
Root MSE: 47.862705

Epoch 74/100
-------------------------------
loss: 1960.458008 [   32/  800]
loss: 2554.870626 [  192/  800]
loss: 2248.135443 [  352/  800]
loss: 2271.218941 [  512/  800]
loss: 2229.134242 [  672/  800]
Epoch complete - average loss: 2174.969023
Root MSE: 47.862940

Epoch 75/100
-------------------------------
loss: 1298.036987 [   32/  800]
loss: 1782.306315 [  192/  800]
loss: 1782.338312 [  352/  800]
loss: 1951.133392 [  512/  800]
loss: 2128.317499 [  672/  800]
Epoch complete - average loss: 2175.050537
Root MSE: 47.863042

Epoch 76/100
-------------------------------
loss: 1442.712524 [   32/  800]
loss: 2076.007426 [  192/  800]
loss: 2142.964455 [  352/  800]
loss: 2068.390160 [  512/  800]
loss: 2140.946975 [  672/  800]
Epoch complete - average loss: 2175.503188
Root MSE: 47.863833

Early stopping at epoch 76
Validation loss didn't improve for 5 epochs.
lowest validation loss: 2290.8298863002233 in epoch 70
lowest training loss: 2174.647763671875 in epoch 71
Training and evaluating model: GRU hidden dimensions: 64, number of layers: 1 on dataset: Non-padding

Epoch 1/100
-------------------------------
loss: 5035.806641 [   32/  795]
loss: 5175.439412 [  192/  795]
loss: 5769.995539 [  352/  795]
loss: 5982.106796 [  512/  795]
loss: 5747.517520 [  672/  795]
/home/dorus/Documenten/UU/Blok 4/deep_learning/Deep-learning-assignment-1/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([27, 1])) that is different to the input size (torch.Size([27])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
Epoch complete - average loss: 5819.254353
Root MSE: 64.633726

Epoch 2/100
-------------------------------
loss: 6486.947754 [   32/  795]
loss: 5230.773031 [  192/  795]
loss: 6062.909490 [  352/  795]
loss: 5935.300079 [  512/  795]
loss: 5576.524216 [  672/  795]
Epoch complete - average loss: 5563.728975
Root MSE: 62.955459

Epoch 3/100
-------------------------------
loss: 8950.161133 [   32/  795]
loss: 6409.417399 [  192/  795]
loss: 5549.320446 [  352/  795]
loss: 5170.882614 [  512/  795]
loss: 5276.920747 [  672/  795]
Epoch complete - average loss: 5294.682574
Root MSE: 61.098687

Epoch 4/100
-------------------------------
loss: 6489.568848 [   32/  795]
loss: 5801.031087 [  192/  795]
loss: 5518.328125 [  352/  795]
loss: 5554.215027 [  512/  795]
loss: 5246.782982 [  672/  795]
Epoch complete - average loss: 5037.163128
Root MSE: 59.584129

Epoch 5/100
-------------------------------
loss: 4878.650391 [   32/  795]
loss: 4712.473755 [  192/  795]
loss: 5143.635454 [  352/  795]
loss: 4883.758911 [  512/  795]
loss: 4778.209136 [  672/  795]
Epoch complete - average loss: 4832.044282
Root MSE: 58.383795

Epoch 6/100
-------------------------------
loss: 5107.403320 [   32/  795]
loss: 3934.808350 [  192/  795]
loss: 4691.926181 [  352/  795]
loss: 4676.032257 [  512/  795]
loss: 4727.939569 [  672/  795]
Epoch complete - average loss: 4663.714509
Root MSE: 57.285305

Epoch 7/100
-------------------------------
loss: 4378.501953 [   32/  795]
loss: 3669.825114 [  192/  795]
loss: 4212.180487 [  352/  795]
loss: 4437.155876 [  512/  795]
loss: 4541.996262 [  672/  795]
Epoch complete - average loss: 4510.376505
Root MSE: 56.276883

Epoch 8/100
-------------------------------
loss: 3433.639648 [   32/  795]
loss: 4305.229818 [  192/  795]
loss: 3896.897616 [  352/  795]
loss: 4081.492401 [  512/  795]
loss: 4093.550851 [  672/  795]
Epoch complete - average loss: 4369.476395
Root MSE: 55.322214

Epoch 9/100
-------------------------------
loss: 5317.908203 [   32/  795]
loss: 4801.714600 [  192/  795]
loss: 4231.002730 [  352/  795]
loss: 4103.545425 [  512/  795]
loss: 4168.149635 [  672/  795]
Epoch complete - average loss: 4238.815959
Root MSE: 54.412074

Epoch 10/100
-------------------------------
loss: 4981.332031 [   32/  795]
loss: 3483.434591 [  192/  795]
loss: 4490.432673 [  352/  795]
loss: 4427.994484 [  512/  795]
loss: 4090.847697 [  672/  795]
Epoch complete - average loss: 4114.226806
Root MSE: 53.545962

Epoch 11/100
-------------------------------
loss: 5221.158203 [   32/  795]
loss: 3649.533040 [  192/  795]
loss: 4104.367654 [  352/  795]
loss: 4156.283768 [  512/  795]
loss: 4119.851766 [  672/  795]
Epoch complete - average loss: 3995.945862
Root MSE: 52.709196

Epoch 12/100
-------------------------------
loss: 3654.669922 [   32/  795]
loss: 3644.629801 [  192/  795]
loss: 3701.285378 [  352/  795]
loss: 3840.415108 [  512/  795]
loss: 3843.573998 [  672/  795]
Epoch complete - average loss: 3875.266115
Root MSE: 51.825687

Epoch 13/100
-------------------------------
loss: 2090.037354 [   32/  795]
loss: 3664.730387 [  192/  795]
loss: 3910.385210 [  352/  795]
loss: 4058.083923 [  512/  795]
loss: 3872.464007 [  672/  795]
Epoch complete - average loss: 3756.126526
Root MSE: 50.982580

Epoch 14/100
-------------------------------
loss: 4061.907715 [   32/  795]
loss: 3801.006063 [  192/  795]
loss: 3986.977472 [  352/  795]
loss: 3726.226395 [  512/  795]
loss: 3646.115711 [  672/  795]
Epoch complete - average loss: 3641.681167
Root MSE: 50.181825

Epoch 15/100
-------------------------------
loss: 3370.269287 [   32/  795]
loss: 3291.781535 [  192/  795]
loss: 3160.827959 [  352/  795]
loss: 3335.485924 [  512/  795]
loss: 3504.419544 [  672/  795]
Epoch complete - average loss: 3536.025748
Root MSE: 49.492971

Epoch 16/100
-------------------------------
loss: 2581.090820 [   32/  795]
loss: 3122.532633 [  192/  795]
loss: 3281.491810 [  352/  795]
loss: 3449.606232 [  512/  795]
loss: 3434.380708 [  672/  795]
Epoch complete - average loss: 3443.832105
Root MSE: 48.821138

Epoch 17/100
-------------------------------
loss: 2162.005859 [   32/  795]
loss: 2641.248861 [  192/  795]
loss: 2915.027155 [  352/  795]
loss: 3439.088341 [  512/  795]
loss: 3356.141479 [  672/  795]
Epoch complete - average loss: 3355.567354
Root MSE: 48.215579

Epoch 18/100
-------------------------------
loss: 1286.912964 [   32/  795]
loss: 3176.188944 [  192/  795]
loss: 2837.627208 [  352/  795]
loss: 3238.697105 [  512/  795]
loss: 3279.699062 [  672/  795]
Epoch complete - average loss: 3274.179077
Root MSE: 47.634080

Epoch 19/100
-------------------------------
loss: 3124.327148 [   32/  795]
loss: 3031.950033 [  192/  795]
loss: 3095.276223 [  352/  795]
loss: 3200.975502 [  512/  795]
loss: 3270.316110 [  672/  795]
Epoch complete - average loss: 3189.986739
Root MSE: 47.036992

Epoch 20/100
-------------------------------
loss: 4998.713379 [   32/  795]
loss: 3360.235006 [  192/  795]
loss: 3160.228948 [  352/  795]
loss: 3172.842491 [  512/  795]
loss: 3176.413522 [  672/  795]
Epoch complete - average loss: 3113.746522
Root MSE: 46.529150

Epoch 21/100
-------------------------------
loss: 4342.942383 [   32/  795]
loss: 3379.362671 [  192/  795]
loss: 3068.614369 [  352/  795]
loss: 3037.703781 [  512/  795]
loss: 3108.859596 [  672/  795]
Epoch complete - average loss: 3043.924626
Root MSE: 46.076885

Epoch 22/100
-------------------------------
loss: 3698.710449 [   32/  795]
loss: 3298.368429 [  192/  795]
loss: 3241.277044 [  352/  795]
loss: 3249.812523 [  512/  795]
loss: 3074.851324 [  672/  795]
Epoch complete - average loss: 2981.986253
Root MSE: 45.646306

Epoch 23/100
-------------------------------
loss: 4296.066895 [   32/  795]
loss: 3102.180603 [  192/  795]
loss: 3069.334684 [  352/  795]
loss: 2898.830040 [  512/  795]
loss: 3022.032837 [  672/  795]
Epoch complete - average loss: 2921.710431
Root MSE: 45.272014

Epoch 24/100
-------------------------------
loss: 2351.833740 [   32/  795]
loss: 3260.468669 [  192/  795]
loss: 3585.463845 [  352/  795]
loss: 3333.569786 [  512/  795]
loss: 2977.300587 [  672/  795]
Epoch complete - average loss: 2867.124914
Root MSE: 44.897823

Epoch 25/100
-------------------------------
loss: 2838.976318 [   32/  795]
loss: 3427.315206 [  192/  795]
loss: 3187.611739 [  352/  795]
loss: 2975.406189 [  512/  795]
loss: 2784.691191 [  672/  795]
Epoch complete - average loss: 2811.593216
Root MSE: 44.574464

Epoch 26/100
-------------------------------
loss: 1845.259888 [   32/  795]
loss: 2402.063375 [  192/  795]
loss: 2570.303389 [  352/  795]
loss: 2905.966240 [  512/  795]
loss: 2785.544817 [  672/  795]
Epoch complete - average loss: 2763.077238
Root MSE: 44.275758

Epoch 27/100
-------------------------------
loss: 2969.927734 [   32/  795]
loss: 3555.146484 [  192/  795]
loss: 3252.307795 [  352/  795]
loss: 2890.766594 [  512/  795]
loss: 2823.633353 [  672/  795]
Epoch complete - average loss: 2716.891022
Root MSE: 44.020902

Epoch 28/100
-------------------------------
loss: 2626.220703 [   32/  795]
loss: 2309.766947 [  192/  795]
loss: 2569.164284 [  352/  795]
loss: 2448.395630 [  512/  795]
loss: 2681.549712 [  672/  795]
Epoch complete - average loss: 2675.710355
Root MSE: 43.795340

Epoch 29/100
-------------------------------
loss: 3395.764648 [   32/  795]
loss: 2888.648397 [  192/  795]
loss: 2664.528132 [  352/  795]
loss: 2383.551987 [  512/  795]
loss: 2521.429850 [  672/  795]
Epoch complete - average loss: 2637.905561
Root MSE: 43.595831

Epoch 30/100
-------------------------------
loss: 1990.374023 [   32/  795]
loss: 2509.490743 [  192/  795]
loss: 2715.552146 [  352/  795]
loss: 2648.389175 [  512/  795]
loss: 2655.126840 [  672/  795]
Epoch complete - average loss: 2603.824974
Root MSE: 43.417616

Epoch 31/100
-------------------------------
loss: 1800.055298 [   32/  795]
loss: 2485.798971 [  192/  795]
loss: 2420.915627 [  352/  795]
loss: 2516.247955 [  512/  795]
loss: 2522.424543 [  672/  795]
Epoch complete - average loss: 2571.067458
Root MSE: 43.267517

Epoch 32/100
-------------------------------
