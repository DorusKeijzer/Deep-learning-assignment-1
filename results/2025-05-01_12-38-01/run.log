Training models:
	1D CNN:
	  <bound method Module.parameters of CNN1DModel(
  (cnn): Sequential(
    (0): Sequential(
      (conv_0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (bn_0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu_0): ReLU()
      (dropout_0): Dropout(p=0.2, inplace=False)
      (adapool_0): AdaptiveAvgPool1d(output_size=1)
    )
    (1): Sequential(
      (conv_1): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (bn_1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu_1): ReLU()
      (dropout_1): Dropout(p=0.2, inplace=False)
      (adapool_1): AdaptiveAvgPool1d(output_size=1)
    )
  )
  (fc): LazyLinear(in_features=0, out_features=1, bias=True)
)>
Using lag parameters: 5
On datasets: Padding, Non-padding
For 100 epochs, with early stopping.
Training and evaluating model: 1D CNN channels: [32, 64], kernels: [3, 3], pooling: max on dataset: Padding

Epoch 1/100
-------------------------------
/home/dorus/Documenten/UU/Blok 4/deep_learning/Deep-learning-assignment-1/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
loss: 6408.378418 [   32/  800]
loss: 6014.732340 [  192/  800]
loss: 5333.055531 [  352/  800]
loss: 5435.496613 [  512/  800]
loss: 5563.093797 [  672/  800]
Epoch complete - average loss: 5680.223867
/home/dorus/Documenten/UU/Blok 4/deep_learning/Deep-learning-assignment-1/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
Root MSE: 75.618354

Epoch 2/100
-------------------------------
loss: 6550.207031 [   32/  800]
loss: 4989.797811 [  192/  800]
loss: 5365.669500 [  352/  800]
loss: 5086.496674 [  512/  800]
loss: 5458.736433 [  672/  800]
Epoch complete - average loss: 5587.472939
Root MSE: 74.790206

Epoch 3/100
-------------------------------
loss: 4662.458496 [   32/  800]
loss: 4472.611247 [  192/  800]
loss: 5145.203214 [  352/  800]
loss: 5206.017487 [  512/  800]
loss: 5228.735561 [  672/  800]
Epoch complete - average loss: 5487.176211
Root MSE: 74.175069

Epoch 4/100
-------------------------------
loss: 7551.193848 [   32/  800]
loss: 5570.947713 [  192/  800]
loss: 5384.830145 [  352/  800]
loss: 5233.679062 [  512/  800]
loss: 5125.034424 [  672/  800]
Epoch complete - average loss: 5376.905205
Root MSE: 73.439948

Epoch 5/100
-------------------------------
loss: 8687.387695 [   32/  800]
loss: 6046.455892 [  192/  800]
loss: 5891.038130 [  352/  800]
loss: 5637.118134 [  512/  800]
loss: 5416.668736 [  672/  800]
Epoch complete - average loss: 5253.741504
Root MSE: 72.585605

Epoch 6/100
-------------------------------
loss: 4276.486816 [   32/  800]
loss: 4988.362264 [  192/  800]
loss: 5065.278121 [  352/  800]
loss: 5171.118515 [  512/  800]
loss: 5165.245989 [  672/  800]
Epoch complete - average loss: 5126.737451
Root MSE: 71.692504

Epoch 7/100
-------------------------------
loss: 4412.851074 [   32/  800]
loss: 3806.025553 [  192/  800]
loss: 4496.264693 [  352/  800]
loss: 4867.086151 [  512/  800]
loss: 4907.260928 [  672/  800]
Epoch complete - average loss: 4989.200957
Root MSE: 70.649885

Epoch 8/100
-------------------------------
loss: 3538.684082 [   32/  800]
loss: 4693.690877 [  192/  800]
loss: 5125.053378 [  352/  800]
loss: 4922.196091 [  512/  800]
loss: 4827.697207 [  672/  800]
Epoch complete - average loss: 4831.369170
Root MSE: 69.491762

Epoch 9/100
-------------------------------
loss: 4228.781250 [   32/  800]
loss: 5927.581299 [  192/  800]
loss: 5291.788685 [  352/  800]
loss: 4938.753525 [  512/  800]
loss: 4733.714448 [  672/  800]
Epoch complete - average loss: 4661.262354
Root MSE: 68.257740

Epoch 10/100
-------------------------------
loss: 4098.187988 [   32/  800]
loss: 4867.423258 [  192/  800]
loss: 4439.118564 [  352/  800]
loss: 4429.924500 [  512/  800]
loss: 4344.294387 [  672/  800]
Epoch complete - average loss: 4480.762031
Root MSE: 66.927602

Epoch 11/100
-------------------------------
loss: 2636.625977 [   32/  800]
loss: 3886.108439 [  192/  800]
loss: 3883.405185 [  352/  800]
loss: 4142.787476 [  512/  800]
loss: 4303.380824 [  672/  800]
Epoch complete - average loss: 4295.263750
Root MSE: 65.530571

Epoch 12/100
-------------------------------
loss: 5254.312012 [   32/  800]
loss: 3748.150472 [  192/  800]
loss: 4220.403853 [  352/  800]
loss: 4190.619919 [  512/  800]
loss: 4161.951288 [  672/  800]
Epoch complete - average loss: 4095.843838
Root MSE: 64.106817

Epoch 13/100
-------------------------------
loss: 4262.159668 [   32/  800]
loss: 2912.706014 [  192/  800]
loss: 3497.624756 [  352/  800]
loss: 3732.768234 [  512/  800]
loss: 3918.917632 [  672/  800]
Epoch complete - average loss: 3919.438516
Root MSE: 62.581915

Epoch 14/100
-------------------------------
loss: 3719.630371 [   32/  800]
loss: 4180.003072 [  192/  800]
loss: 4009.907704 [  352/  800]
loss: 3996.664024 [  512/  800]
loss: 3780.441569 [  672/  800]
Epoch complete - average loss: 3732.575156
Root MSE: 60.984058

Epoch 15/100
-------------------------------
loss: 2644.342041 [   32/  800]
loss: 3441.516520 [  192/  800]
loss: 3297.657393 [  352/  800]
loss: 3393.151649 [  512/  800]
loss: 3464.127924 [  672/  800]
Epoch complete - average loss: 3536.502964
Root MSE: 59.742061

Epoch 16/100
-------------------------------
loss: 2446.338379 [   32/  800]
loss: 3969.773722 [  192/  800]
loss: 3793.844782 [  352/  800]
loss: 3330.786858 [  512/  800]
loss: 3357.386666 [  672/  800]
Epoch complete - average loss: 3364.232471
Root MSE: 58.232952

Epoch 17/100
-------------------------------
loss: 3389.233154 [   32/  800]
loss: 3396.873250 [  192/  800]
loss: 3330.884388 [  352/  800]
loss: 3618.847977 [  512/  800]
loss: 3390.274472 [  672/  800]
Epoch complete - average loss: 3211.904573
Root MSE: 56.835117

Epoch 18/100
-------------------------------
loss: 1830.464355 [   32/  800]
loss: 2998.546794 [  192/  800]
loss: 3142.469793 [  352/  800]
loss: 3153.210495 [  512/  800]
loss: 3061.227830 [  672/  800]
Epoch complete - average loss: 3042.567881
Root MSE: 55.613949

Epoch 19/100
-------------------------------
loss: 2878.539795 [   32/  800]
loss: 3325.861003 [  192/  800]
loss: 2787.271262 [  352/  800]
loss: 2764.347519 [  512/  800]
loss: 2927.223482 [  672/  800]
Epoch complete - average loss: 2916.444077
Root MSE: 54.354811

Epoch 20/100
-------------------------------
loss: 1930.911621 [   32/  800]
loss: 2207.120605 [  192/  800]
loss: 2639.115123 [  352/  800]
loss: 2735.894798 [  512/  800]
loss: 2772.440871 [  672/  800]
Epoch complete - average loss: 2783.545571
Root MSE: 53.193769

Epoch 21/100
-------------------------------
loss: 1216.818237 [   32/  800]
loss: 2861.675456 [  192/  800]
loss: 2922.444114 [  352/  800]
loss: 2829.579781 [  512/  800]
loss: 2783.893206 [  672/  800]
Epoch complete - average loss: 2681.083315
Root MSE: 52.272479

Epoch 22/100
-------------------------------
loss: 3879.004150 [   32/  800]
loss: 2864.400981 [  192/  800]
loss: 2489.039895 [  352/  800]
loss: 2586.493385 [  512/  800]
loss: 2563.684588 [  672/  800]
Epoch complete - average loss: 2589.814019
Root MSE: 51.354813

Epoch 23/100
-------------------------------
loss: 3199.080566 [   32/  800]
loss: 2838.077148 [  192/  800]
loss: 2429.382735 [  352/  800]
loss: 2412.408096 [  512/  800]
loss: 2694.557826 [  672/  800]
Epoch complete - average loss: 2507.128828
Root MSE: 50.695051

Epoch 24/100
-------------------------------
loss: 1205.359863 [   32/  800]
loss: 2009.691182 [  192/  800]
loss: 1995.651034 [  352/  800]
loss: 2082.955551 [  512/  800]
loss: 2391.138253 [  672/  800]
Epoch complete - average loss: 2436.279302
Root MSE: 50.048306

Epoch 25/100
-------------------------------
loss: 2489.344238 [   32/  800]
loss: 2571.184285 [  192/  800]
loss: 2535.363398 [  352/  800]
loss: 2538.366291 [  512/  800]
loss: 2445.982553 [  672/  800]
Epoch complete - average loss: 2394.638289
Root MSE: 49.768598

Epoch 26/100
-------------------------------
loss: 2539.495605 [   32/  800]
loss: 1873.269399 [  192/  800]
loss: 2156.207336 [  352/  800]
loss: 2122.832714 [  512/  800]
loss: 2276.257403 [  672/  800]
Epoch complete - average loss: 2336.174968
Root MSE: 49.111068

Epoch 27/100
-------------------------------
loss: 1715.375366 [   32/  800]
loss: 2126.057699 [  192/  800]
loss: 2326.629150 [  352/  800]
loss: 2348.395157 [  512/  800]
loss: 2395.347528 [  672/  800]
Epoch complete - average loss: 2308.249780
Root MSE: 48.931144

Epoch 28/100
-------------------------------
loss: 1792.762817 [   32/  800]
loss: 2734.608663 [  192/  800]
loss: 2334.583884 [  352/  800]
loss: 2241.537971 [  512/  800]
loss: 2270.040597 [  672/  800]
Epoch complete - average loss: 2284.363926
Root MSE: 48.709227

Epoch 29/100
-------------------------------
loss: 2024.366943 [   32/  800]
loss: 2441.196899 [  192/  800]
loss: 2266.524902 [  352/  800]
loss: 2388.616608 [  512/  800]
loss: 2328.352028 [  672/  800]
Epoch complete - average loss: 2263.240420
Root MSE: 48.432082

Epoch 30/100
-------------------------------
loss: 3670.540039 [   32/  800]
loss: 2360.115946 [  192/  800]
loss: 2441.018000 [  352/  800]
loss: 2287.110077 [  512/  800]
loss: 2211.884056 [  672/  800]
Epoch complete - average loss: 2245.287759
Root MSE: 48.351882

Epoch 31/100
-------------------------------
loss: 1165.345215 [   32/  800]
loss: 2003.937663 [  192/  800]
loss: 2084.209672 [  352/  800]
loss: 1946.275490 [  512/  800]
loss: 2097.709019 [  672/  800]
Epoch complete - average loss: 2230.529326
Root MSE: 48.251219

Epoch 32/100
-------------------------------
loss: 1401.097778 [   32/  800]
loss: 2347.563029 [  192/  800]
loss: 2294.232466 [  352/  800]
loss: 2258.366844 [  512/  800]
loss: 2240.311204 [  672/  800]
Epoch complete - average loss: 2233.621885
Root MSE: 48.205959

Epoch 33/100
-------------------------------
loss: 2608.296143 [   32/  800]
loss: 2512.069519 [  192/  800]
loss: 2359.496560 [  352/  800]
loss: 2437.540535 [  512/  800]
loss: 2302.782750 [  672/  800]
Epoch complete - average loss: 2215.800366
Root MSE: 48.128314

Epoch 34/100
-------------------------------
loss: 2172.261719 [   32/  800]
loss: 2215.167196 [  192/  800]
loss: 2313.473888 [  352/  800]
loss: 2123.782745 [  512/  800]
loss: 2122.526042 [  672/  800]
Epoch complete - average loss: 2220.814688
Root MSE: 48.094342

Epoch 35/100
-------------------------------
loss: 2180.638916 [   32/  800]
loss: 2161.050354 [  192/  800]
loss: 2107.713956 [  352/  800]
loss: 2211.010223 [  512/  800]
loss: 2251.619042 [  672/  800]
Epoch complete - average loss: 2211.236021
Root MSE: 48.062803

Epoch 36/100
-------------------------------
loss: 1922.919189 [   32/  800]
loss: 1721.510071 [  192/  800]
loss: 2047.063710 [  352/  800]
loss: 2174.804825 [  512/  800]
loss: 2187.539394 [  672/  800]
Epoch complete - average loss: 2208.561938
Root MSE: 48.036427

Epoch 37/100
-------------------------------
loss: 2279.054688 [   32/  800]
loss: 1938.826457 [  192/  800]
loss: 2177.284535 [  352/  800]
loss: 2173.486359 [  512/  800]
loss: 2167.710955 [  672/  800]
Epoch complete - average loss: 2213.380781
Root MSE: 48.045546

Epoch 38/100
-------------------------------
loss: 2232.687012 [   32/  800]
loss: 1830.026062 [  192/  800]
loss: 1974.195601 [  352/  800]
loss: 2152.337563 [  512/  800]
loss: 2171.105881 [  672/  800]
Epoch complete - average loss: 2213.577505
Root MSE: 48.033361

Epoch 39/100
-------------------------------
loss: 2290.421143 [   32/  800]
loss: 2290.218974 [  192/  800]
loss: 2292.413386 [  352/  800]
loss: 2216.808739 [  512/  800]
loss: 2263.437988 [  672/  800]
Epoch complete - average loss: 2208.853232
Root MSE: 47.977244

Epoch 40/100
-------------------------------
loss: 1671.217896 [   32/  800]
loss: 2251.573486 [  192/  800]
loss: 2257.845126 [  352/  800]
loss: 2265.731850 [  512/  800]
loss: 2202.090687 [  672/  800]
Epoch complete - average loss: 2211.350034
Root MSE: 47.975962

Epoch 41/100
-------------------------------
loss: 1844.637451 [   32/  800]
loss: 2201.313599 [  192/  800]
loss: 2402.132724 [  352/  800]
loss: 2157.900299 [  512/  800]
loss: 2231.579601 [  672/  800]
Epoch complete - average loss: 2208.524937
Root MSE: 47.994316

Epoch 42/100
-------------------------------
loss: 3407.356201 [   32/  800]
loss: 2243.842122 [  192/  800]
loss: 2359.393200 [  352/  800]
loss: 2221.860992 [  512/  800]
loss: 2173.063215 [  672/  800]
Epoch complete - average loss: 2210.261694
Root MSE: 47.987104

Epoch 43/100
-------------------------------
loss: 2367.499268 [   32/  800]
loss: 2136.592712 [  192/  800]
loss: 2016.484952 [  352/  800]
loss: 2224.257095 [  512/  800]
loss: 2236.443598 [  672/  800]
Epoch complete - average loss: 2206.874961
Root MSE: 47.996745

Epoch 44/100
-------------------------------
loss: 1746.677856 [   32/  800]
loss: 2007.462077 [  192/  800]
loss: 2115.970947 [  352/  800]
loss: 2177.182098 [  512/  800]
loss: 2197.571388 [  672/  800]
Epoch complete - average loss: 2207.590547
Root MSE: 47.955563

Epoch 45/100
-------------------------------
loss: 3690.530518 [   32/  800]
loss: 2807.671672 [  192/  800]
loss: 2398.176170 [  352/  800]
loss: 2408.320129 [  512/  800]
loss: 2194.810512 [  672/  800]
Epoch complete - average loss: 2208.437605
Root MSE: 47.970874

Epoch 46/100
-------------------------------
loss: 2482.145508 [   32/  800]
loss: 2275.976481 [  192/  800]
loss: 2148.864691 [  352/  800]
loss: 2189.655975 [  512/  800]
loss: 2224.659063 [  672/  800]
Epoch complete - average loss: 2210.606641
Root MSE: 47.979818

Epoch 47/100
-------------------------------
loss: 1560.638672 [   32/  800]
loss: 2160.863708 [  192/  800]
loss: 2193.338656 [  352/  800]
loss: 2250.578415 [  512/  800]
loss: 2217.889056 [  672/  800]
Epoch complete - average loss: 2196.596968
Root MSE: 47.978555

Epoch 48/100
-------------------------------
loss: 1899.665161 [   32/  800]
loss: 2628.279093 [  192/  800]
loss: 2433.579013 [  352/  800]
loss: 2349.671371 [  512/  800]
loss: 2272.862206 [  672/  800]
Epoch complete - average loss: 2205.133032
Root MSE: 47.977991

Epoch 49/100
-------------------------------
loss: 1952.243530 [   32/  800]
loss: 2005.004679 [  192/  800]
loss: 2134.194358 [  352/  800]
loss: 2099.480080 [  512/  800]
loss: 2203.716280 [  672/  800]
Epoch complete - average loss: 2205.692881
Root MSE: 47.967877

Early stopping at epoch 49
Validation loss didn't improve for 5 epochs.
lowest validation loss: 2299.736066545759 in epoch 43
lowest training loss: 2196.5969677734374 in epoch 46
Training and evaluating model: 1D CNN channels: [32, 64], kernels: [3, 3], pooling: max on dataset: Non-padding

Epoch 1/100
-------------------------------
loss: 6190.295898 [   32/  795]
loss: 5442.758830 [  192/  795]
loss: 6397.493896 [  352/  795]
loss: 6402.131088 [  512/  795]
loss: 5965.946184 [  672/  795]
/home/dorus/Documenten/UU/Blok 4/deep_learning/Deep-learning-assignment-1/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([27, 1])) that is different to the input size (torch.Size([27])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
Epoch complete - average loss: 5960.642824
Root MSE: 66.255876

Epoch 2/100
-------------------------------
loss: 5585.952637 [   32/  795]
loss: 6415.789062 [  192/  795]
loss: 6275.040661 [  352/  795]
loss: 6225.071716 [  512/  795]
loss: 6020.889183 [  672/  795]
Epoch complete - average loss: 5868.343967
Root MSE: 65.654198

Epoch 3/100
-------------------------------
loss: 5268.106445 [   32/  795]
loss: 5693.570231 [  192/  795]
loss: 5997.326172 [  352/  795]
loss: 5946.549393 [  512/  795]
loss: 5832.533529 [  672/  795]
Epoch complete - average loss: 5774.540758
Root MSE: 65.072920

Epoch 4/100
-------------------------------
loss: 5392.138672 [   32/  795]
loss: 6271.924316 [  192/  795]
loss: 6035.380948 [  352/  795]
loss: 5863.246323 [  512/  795]
loss: 5735.967355 [  672/  795]
Epoch complete - average loss: 5674.325505
Root MSE: 64.392694

Epoch 5/100
-------------------------------
loss: 8143.363281 [   32/  795]
loss: 5901.814046 [  192/  795]
loss: 5603.168857 [  352/  795]
loss: 5788.443115 [  512/  795]
loss: 5645.725319 [  672/  795]
Epoch complete - average loss: 5560.195791
Root MSE: 63.614508

Epoch 6/100
-------------------------------
loss: 6630.643555 [   32/  795]
loss: 5889.707194 [  192/  795]
loss: 6001.442738 [  352/  795]
loss: 5659.603912 [  512/  795]
loss: 5512.781948 [  672/  795]
Epoch complete - average loss: 5439.669321
Root MSE: 62.926004

Epoch 7/100
-------------------------------
loss: 3080.000732 [   32/  795]
loss: 4729.577515 [  192/  795]
loss: 4921.989635 [  352/  795]
loss: 4938.854385 [  512/  795]
loss: 4935.017264 [  672/  795]
Epoch complete - average loss: 5294.716059
Root MSE: 61.980736

Epoch 8/100
-------------------------------
loss: 3874.916504 [   32/  795]
loss: 5389.180176 [  192/  795]
loss: 5156.315962 [  352/  795]
loss: 5468.828247 [  512/  795]
loss: 5289.070464 [  672/  795]
Epoch complete - average loss: 5142.542737
Root MSE: 60.916067

Epoch 9/100
-------------------------------
loss: 7259.326172 [   32/  795]
loss: 5157.809001 [  192/  795]
loss: 5428.050781 [  352/  795]
loss: 4985.449234 [  512/  795]
loss: 4961.461728 [  672/  795]
Epoch complete - average loss: 4973.754433
Root MSE: 59.762726

Epoch 10/100
-------------------------------
loss: 5260.487305 [   32/  795]
loss: 4919.510661 [  192/  795]
loss: 4780.342463 [  352/  795]
loss: 4781.738663 [  512/  795]
loss: 4679.837670 [  672/  795]
Epoch complete - average loss: 4787.298458
Root MSE: 58.418406

Epoch 11/100
-------------------------------
loss: 3139.463867 [   32/  795]
loss: 4077.212646 [  192/  795]
loss: 4281.850763 [  352/  795]
loss: 4729.737854 [  512/  795]
loss: 4587.636184 [  672/  795]
Epoch complete - average loss: 4595.215727
Root MSE: 57.179911

Epoch 12/100
-------------------------------
loss: 5697.004395 [   32/  795]
loss: 4796.639364 [  192/  795]
loss: 4527.694713 [  352/  795]
loss: 4384.670517 [  512/  795]
loss: 4209.983526 [  672/  795]
Epoch complete - average loss: 4390.917545
Root MSE: 55.783808

Epoch 13/100
-------------------------------
loss: 2823.468994 [   32/  795]
loss: 3960.804850 [  192/  795]
loss: 3856.153520 [  352/  795]
loss: 3929.695709 [  512/  795]
loss: 4161.094366 [  672/  795]
Epoch complete - average loss: 4191.940463
Root MSE: 54.222836

Epoch 14/100
-------------------------------
loss: 3453.526123 [   32/  795]
loss: 4287.785929 [  192/  795]
loss: 3988.167037 [  352/  795]
loss: 4096.683624 [  512/  795]
loss: 3978.884591 [  672/  795]
Epoch complete - average loss: 3990.261962
Root MSE: 52.882156

Epoch 15/100
-------------------------------
loss: 5742.356445 [   32/  795]
loss: 3992.755005 [  192/  795]
loss: 4198.014981 [  352/  795]
loss: 4001.193756 [  512/  795]
loss: 3966.928688 [  672/  795]
Epoch complete - average loss: 3785.085758
Root MSE: 51.439643

Epoch 16/100
-------------------------------
loss: 5548.943359 [   32/  795]
loss: 3294.615662 [  192/  795]
loss: 3457.904552 [  352/  795]
loss: 3425.776527 [  512/  795]
loss: 3384.984067 [  672/  795]
Epoch complete - average loss: 3604.102297
Root MSE: 49.857561

Epoch 17/100
-------------------------------
loss: 3411.928223 [   32/  795]
loss: 3743.235433 [  192/  795]
loss: 3302.870306 [  352/  795]
loss: 3324.471718 [  512/  795]
loss: 3356.337420 [  672/  795]
Epoch complete - average loss: 3427.560871
Root MSE: 48.701840

Epoch 18/100
-------------------------------
loss: 3774.670898 [   32/  795]
loss: 3246.233276 [  192/  795]
loss: 3393.106556 [  352/  795]
loss: 3287.482376 [  512/  795]
loss: 3261.441034 [  672/  795]
Epoch complete - average loss: 3250.861992
Root MSE: 47.324832

Epoch 19/100
-------------------------------
loss: 3247.640625 [   32/  795]
loss: 3625.917542 [  192/  795]
loss: 3170.622093 [  352/  795]
loss: 3247.020645 [  512/  795]
loss: 3065.886783 [  672/  795]
Epoch complete - average loss: 3100.752814
Root MSE: 46.351245

Epoch 20/100
-------------------------------
loss: 3646.309814 [   32/  795]
loss: 3082.352519 [  192/  795]
loss: 2960.492099 [  352/  795]
loss: 3062.351227 [  512/  795]
loss: 2904.053141 [  672/  795]
Epoch complete - average loss: 2963.723355
Root MSE: 45.409088

Epoch 21/100
-------------------------------
loss: 4865.622070 [   32/  795]
loss: 3628.151978 [  192/  795]
loss: 2900.833230 [  352/  795]
loss: 3013.063004 [  512/  795]
loss: 2926.826788 [  672/  795]
Epoch complete - average loss: 2843.936218
Root MSE: 44.703975

Epoch 22/100
-------------------------------
loss: 4069.400391 [   32/  795]
loss: 2850.169474 [  192/  795]
loss: 2717.561191 [  352/  795]
loss: 2672.921722 [  512/  795]
loss: 2731.215413 [  672/  795]
Epoch complete - average loss: 2739.419389
Root MSE: 44.114281

Epoch 23/100
-------------------------------
loss: 1959.641968 [   32/  795]
loss: 2786.868306 [  192/  795]
loss: 2858.520963 [  352/  795]
loss: 2742.610672 [  512/  795]
loss: 2586.741647 [  672/  795]
Epoch complete - average loss: 2646.897366
Root MSE: 43.593067

Epoch 24/100
-------------------------------
loss: 1861.073730 [   32/  795]
loss: 2216.384725 [  192/  795]
loss: 2392.777455 [  352/  795]
loss: 2429.189598 [  512/  795]
loss: 2562.937901 [  672/  795]
Epoch complete - average loss: 2578.262382
Root MSE: 43.178637

Epoch 25/100
-------------------------------
loss: 1428.486694 [   32/  795]
loss: 2567.811096 [  192/  795]
loss: 2426.846458 [  352/  795]
loss: 2361.436241 [  512/  795]
loss: 2417.059640 [  672/  795]
Epoch complete - average loss: 2515.319640
Root MSE: 42.915464

Epoch 26/100
-------------------------------
loss: 2319.912354 [   32/  795]
loss: 2251.364889 [  192/  795]
loss: 2346.316750 [  352/  795]
loss: 2364.799248 [  512/  795]
loss: 2475.703881 [  672/  795]
Epoch complete - average loss: 2464.026681
Root MSE: 42.796918

Epoch 27/100
-------------------------------
loss: 2257.610107 [   32/  795]
loss: 2246.438822 [  192/  795]
loss: 2675.421686 [  352/  795]
loss: 2485.149536 [  512/  795]
loss: 2378.506319 [  672/  795]
Epoch complete - average loss: 2422.908909
Root MSE: 42.640808

Epoch 28/100
-------------------------------
loss: 1496.585938 [   32/  795]
loss: 2300.006470 [  192/  795]
loss: 2489.699807 [  352/  795]
loss: 2492.096176 [  512/  795]
loss: 2421.288028 [  672/  795]
Epoch complete - average loss: 2398.938822
Root MSE: 42.601057

Epoch 29/100
-------------------------------
loss: 1778.935303 [   32/  795]
loss: 2122.603129 [  192/  795]
loss: 2492.782304 [  352/  795]
loss: 2385.721718 [  512/  795]
loss: 2319.990316 [  672/  795]
Epoch complete - average loss: 2359.470336
Root MSE: 42.684366

Epoch 30/100
-------------------------------
loss: 2677.416260 [   32/  795]
loss: 2541.549927 [  192/  795]
loss: 2331.572610 [  352/  795]
loss: 2245.303253 [  512/  795]
loss: 2246.655119 [  672/  795]
Epoch complete - average loss: 2344.802581
Root MSE: 42.629204

Epoch 31/100
-------------------------------
loss: 2461.631348 [   32/  795]
loss: 2469.026042 [  192/  795]
loss: 2432.647627 [  352/  795]
loss: 2277.299484 [  512/  795]
loss: 2332.889997 [  672/  795]
Epoch complete - average loss: 2340.371173
Root MSE: 42.794229

Epoch 32/100
-------------------------------
loss: 2781.714844 [   32/  795]
loss: 2183.395467 [  192/  795]
loss: 2270.896873 [  352/  795]
loss: 2517.026039 [  512/  795]
loss: 2366.330439 [  672/  795]
Epoch complete - average loss: 2325.820739
Root MSE: 42.826900

Epoch 33/100
-------------------------------
loss: 2742.568115 [   32/  795]
loss: 2807.315247 [  192/  795]
loss: 2744.564864 [  352/  795]
loss: 2405.944763 [  512/  795]
loss: 2294.698626 [  672/  795]
Epoch complete - average loss: 2317.372046
Root MSE: 43.021547

Early stopping at epoch 33
Validation loss didn't improve for 5 epochs.
lowest validation loss: 1814.8500453404017 in epoch 27
lowest training loss: 2317.3720463590803 in epoch 32
