Training models:
	most recent baseline:
	  <bound method Module.parameters of MostRecentBaseline()>
	Mean Baseline:
	  <bound method Module.parameters of MeanBaseline()>
	GRU:
	  <bound method Module.parameters of GRUModel(
  (gru): GRU(1, 64, batch_first=True)
  (fc): Linear(in_features=64, out_features=1, bias=True)
)>
	GRU:
	  <bound method Module.parameters of GRUModel(
  (gru): GRU(1, 64, num_layers=2, batch_first=True)
  (fc): Linear(in_features=64, out_features=1, bias=True)
)>
	GRU:
	  <bound method Module.parameters of GRUModel(
  (gru): GRU(1, 64, num_layers=3, batch_first=True)
  (fc): Linear(in_features=64, out_features=1, bias=True)
)>
	GRU:
	  <bound method Module.parameters of GRUModel(
  (gru): GRU(1, 64, num_layers=4, batch_first=True)
  (fc): Linear(in_features=64, out_features=1, bias=True)
)>
	1D CNN:
	  <bound method Module.parameters of CNN1DModel(
  (cnn): Sequential(
    (0): Sequential(
      (conv_0): Conv1d(1, 32, kernel_size=(3,), stride=(1,), padding=(1,))
      (bn_0): BatchNorm1d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu_0): ReLU()
      (dropout_0): Dropout(p=0.2, inplace=False)
      (adapool_0): AdaptiveAvgPool1d(output_size=1)
    )
    (1): Sequential(
      (conv_1): Conv1d(32, 64, kernel_size=(3,), stride=(1,), padding=(1,))
      (bn_1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu_1): ReLU()
      (dropout_1): Dropout(p=0.2, inplace=False)
      (adapool_1): AdaptiveAvgPool1d(output_size=1)
    )
  )
  (fc): LazyLinear(in_features=0, out_features=1, bias=True)
)>
Using lag parameters: 5
On datasets: Padding, Non-padding
For 100 epochs, with early stopping.
Training and evaluating model: most recent baseline  on dataset: Padding
/home/dorus/Documenten/UU/Blok 4/deep_learning/Deep-learning-assignment-1/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
/home/dorus/Documenten/UU/Blok 4/deep_learning/Deep-learning-assignment-1/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8, 5])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
Root MSE: 76.276705
Training and evaluating model: most recent baseline  on dataset: Non-padding
Root MSE: 72.645237
Training and evaluating model: Mean Baseline  on dataset: Padding
Root MSE: 76.276705
Training and evaluating model: Mean Baseline  on dataset: Non-padding
Root MSE: 72.645237
Training and evaluating model: GRU hidden dimensions: 64, number of layers: 1 on dataset: Padding

Epoch 1/100
-------------------------------
/home/dorus/Documenten/UU/Blok 4/deep_learning/Deep-learning-assignment-1/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([32, 1])) that is different to the input size (torch.Size([32])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
loss: 9367.931641 [   32/  800]
loss: 5929.278890 [  192/  800]
loss: 6051.349521 [  352/  800]
loss: 6067.325180 [  512/  800]
loss: 5813.835496 [  672/  800]
Epoch complete - average loss: 5672.690303
/home/dorus/Documenten/UU/Blok 4/deep_learning/Deep-learning-assignment-1/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([8, 1])) that is different to the input size (torch.Size([8])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
Root MSE: 74.703684

Epoch 2/100
-------------------------------
loss: 5929.422363 [   32/  800]
loss: 5553.997640 [  192/  800]
loss: 5412.000355 [  352/  800]
loss: 5377.587646 [  512/  800]
loss: 5528.108468 [  672/  800]
Epoch complete - average loss: 5457.091914
Root MSE: 73.232754

Epoch 3/100
-------------------------------
loss: 6547.443848 [   32/  800]
loss: 5049.846354 [  192/  800]
loss: 5392.312522 [  352/  800]
loss: 5262.209183 [  512/  800]
loss: 5172.884219 [  672/  800]
Epoch complete - average loss: 5220.981846
Root MSE: 71.604012

Epoch 4/100
-------------------------------
loss: 4996.214355 [   32/  800]
loss: 4793.004313 [  192/  800]
loss: 4921.748358 [  352/  800]
loss: 4950.364380 [  512/  800]
loss: 4848.575358 [  672/  800]
Epoch complete - average loss: 4994.568477
Root MSE: 70.203621

Epoch 5/100
-------------------------------
loss: 4634.004883 [   32/  800]
loss: 5221.799561 [  192/  800]
loss: 4608.047985 [  352/  800]
loss: 4719.281219 [  512/  800]
loss: 4766.927153 [  672/  800]
Epoch complete - average loss: 4796.522598
Root MSE: 68.865633

Epoch 6/100
-------------------------------
loss: 4642.060547 [   32/  800]
loss: 4017.998047 [  192/  800]
loss: 4098.447554 [  352/  800]
loss: 4554.276291 [  512/  800]
loss: 4830.733468 [  672/  800]
Epoch complete - average loss: 4626.250781
Root MSE: 67.736126

Epoch 7/100
-------------------------------
loss: 5494.844727 [   32/  800]
loss: 4513.543457 [  192/  800]
loss: 4512.703880 [  352/  800]
loss: 4722.509995 [  512/  800]
loss: 4410.759952 [  672/  800]
Epoch complete - average loss: 4476.781143
Root MSE: 66.656910

Epoch 8/100
-------------------------------
loss: 3402.063965 [   32/  800]
loss: 4690.562012 [  192/  800]
loss: 4218.862105 [  352/  800]
loss: 4124.033554 [  512/  800]
loss: 4215.234677 [  672/  800]
Epoch complete - average loss: 4322.323955
Root MSE: 65.498833

Epoch 9/100
-------------------------------
loss: 3167.320068 [   32/  800]
loss: 4156.953613 [  192/  800]
loss: 3812.071467 [  352/  800]
loss: 3875.090958 [  512/  800]
loss: 3895.232230 [  672/  800]
Epoch complete - average loss: 4169.761655
Root MSE: 64.312896

Epoch 10/100
-------------------------------
loss: 1600.887695 [   32/  800]
loss: 4331.984049 [  192/  800]
loss: 4100.751887 [  352/  800]
loss: 4411.255707 [  512/  800]
loss: 4223.581264 [  672/  800]
Epoch complete - average loss: 4010.240542
Root MSE: 63.082469

Epoch 11/100
-------------------------------
loss: 3586.273193 [   32/  800]
loss: 3582.689535 [  192/  800]
loss: 3613.456965 [  352/  800]
loss: 3974.234848 [  512/  800]
loss: 3933.450997 [  672/  800]
Epoch complete - average loss: 3863.710117
Root MSE: 62.037305

Epoch 12/100
-------------------------------
loss: 2819.484619 [   32/  800]
loss: 3707.918457 [  192/  800]
loss: 4221.195934 [  352/  800]
loss: 3941.313675 [  512/  800]
loss: 3820.116874 [  672/  800]
Epoch complete - average loss: 3728.213545
Root MSE: 60.923244

Epoch 13/100
-------------------------------
loss: 7152.005371 [   32/  800]
loss: 4641.858032 [  192/  800]
loss: 4281.126998 [  352/  800]
loss: 4201.319130 [  512/  800]
loss: 3730.762527 [  672/  800]
Epoch complete - average loss: 3601.051016
Root MSE: 59.958299

Epoch 14/100
-------------------------------
loss: 3200.553467 [   32/  800]
loss: 3275.479085 [  192/  800]
loss: 3350.002075 [  352/  800]
loss: 3438.971794 [  512/  800]
loss: 3407.461315 [  672/  800]
Epoch complete - average loss: 3485.224653
Root MSE: 59.104174

Epoch 15/100
-------------------------------
loss: 4581.314453 [   32/  800]
loss: 3689.703979 [  192/  800]
loss: 3295.618164 [  352/  800]
loss: 3546.496155 [  512/  800]
loss: 3495.155390 [  672/  800]
Epoch complete - average loss: 3384.344409
Root MSE: 58.269871

Epoch 16/100
-------------------------------
loss: 2041.603027 [   32/  800]
loss: 2492.128194 [  192/  800]
loss: 2943.361439 [  352/  800]
loss: 3387.026062 [  512/  800]
loss: 3419.659238 [  672/  800]
Epoch complete - average loss: 3286.325518
Root MSE: 57.437185

Epoch 17/100
-------------------------------
loss: 3036.324219 [   32/  800]
loss: 3294.754150 [  192/  800]
loss: 3104.699330 [  352/  800]
loss: 3206.179886 [  512/  800]
loss: 3222.829973 [  672/  800]
Epoch complete - average loss: 3192.370615
Root MSE: 56.706454

Epoch 18/100
-------------------------------
loss: 3000.237793 [   32/  800]
loss: 3259.101400 [  192/  800]
loss: 3065.905396 [  352/  800]
loss: 3171.790062 [  512/  800]
loss: 3039.165487 [  672/  800]
Epoch complete - average loss: 3108.131069
Root MSE: 56.001741

Epoch 19/100
-------------------------------
loss: 5387.557617 [   32/  800]
loss: 2551.337911 [  192/  800]
loss: 2880.838634 [  352/  800]
loss: 2946.660072 [  512/  800]
loss: 3044.504819 [  672/  800]
Epoch complete - average loss: 3030.693486
Root MSE: 55.359642

Epoch 20/100
-------------------------------
loss: 3316.382812 [   32/  800]
loss: 2806.764587 [  192/  800]
loss: 2878.113237 [  352/  800]
loss: 2867.068398 [  512/  800]
loss: 2888.188168 [  672/  800]
Epoch complete - average loss: 2959.477954
Root MSE: 54.758654

Epoch 21/100
-------------------------------
loss: 3156.594238 [   32/  800]
loss: 2784.234904 [  192/  800]
loss: 3006.569991 [  352/  800]
loss: 2864.282234 [  512/  800]
loss: 2930.110695 [  672/  800]
Epoch complete - average loss: 2893.629470
Root MSE: 54.190772

Epoch 22/100
-------------------------------
loss: 3690.901367 [   32/  800]
loss: 2841.710551 [  192/  800]
loss: 2725.830089 [  352/  800]
loss: 2853.762123 [  512/  800]
loss: 2740.702480 [  672/  800]
Epoch complete - average loss: 2834.577202
Root MSE: 53.660481

Epoch 23/100
-------------------------------
loss: 4747.115723 [   32/  800]
loss: 3410.165365 [  192/  800]
loss: 3039.238437 [  352/  800]
loss: 2974.477127 [  512/  800]
loss: 2868.956671 [  672/  800]
Epoch complete - average loss: 2776.757100
Root MSE: 53.153330

Epoch 24/100
-------------------------------
loss: 1880.740479 [   32/  800]
loss: 2976.702698 [  192/  800]
loss: 2587.732722 [  352/  800]
loss: 2430.442909 [  512/  800]
loss: 2679.083083 [  672/  800]
Epoch complete - average loss: 2722.772622
Root MSE: 52.718614

Epoch 25/100
-------------------------------
loss: 1641.711426 [   32/  800]
loss: 2971.311483 [  192/  800]
loss: 2707.633456 [  352/  800]
loss: 2625.657341 [  512/  800]
loss: 2620.379191 [  672/  800]
Epoch complete - average loss: 2676.393745
Root MSE: 52.289354

Epoch 26/100
-------------------------------
loss: 3130.652100 [   32/  800]
loss: 2577.802063 [  192/  800]
loss: 2730.737771 [  352/  800]
loss: 2606.963394 [  512/  800]
loss: 2551.424805 [  672/  800]
Epoch complete - average loss: 2631.514434
Root MSE: 51.884883

Epoch 27/100
-------------------------------
loss: 2978.982666 [   32/  800]
loss: 2601.225932 [  192/  800]
loss: 2595.733765 [  352/  800]
loss: 2647.084976 [  512/  800]
loss: 2584.638684 [  672/  800]
Epoch complete - average loss: 2589.488530
Root MSE: 51.520109

Epoch 28/100
-------------------------------
loss: 3344.041992 [   32/  800]
loss: 2853.535197 [  192/  800]
loss: 2876.579501 [  352/  800]
loss: 2684.320885 [  512/  800]
loss: 2613.037121 [  672/  800]
Epoch complete - average loss: 2552.317100
Root MSE: 51.176377

Epoch 29/100
-------------------------------
loss: 1821.965332 [   32/  800]
loss: 2399.693868 [  192/  800]
loss: 2429.073420 [  352/  800]
loss: 2425.548027 [  512/  800]
loss: 2622.449294 [  672/  800]
Epoch complete - average loss: 2517.519360
Root MSE: 50.859471

Epoch 30/100
-------------------------------
loss: 3404.492920 [   32/  800]
loss: 2721.610209 [  192/  800]
loss: 2636.977783 [  352/  800]
loss: 2611.365425 [  512/  800]
loss: 2413.050281 [  672/  800]
Epoch complete - average loss: 2484.318613
Root MSE: 50.571793

Epoch 31/100
-------------------------------
loss: 3414.587891 [   32/  800]
loss: 2465.279765 [  192/  800]
loss: 2346.544090 [  352/  800]
loss: 2369.021103 [  512/  800]
loss: 2485.841111 [  672/  800]
Epoch complete - average loss: 2454.430947
Root MSE: 50.310916

Epoch 32/100
-------------------------------
loss: 3428.390137 [   32/  800]
loss: 2253.178589 [  192/  800]
loss: 2102.839605 [  352/  800]
loss: 2209.917400 [  512/  800]
loss: 2299.585289 [  672/  800]
Epoch complete - average loss: 2426.512019
Root MSE: 50.068058

Epoch 33/100
-------------------------------
loss: 1462.621338 [   32/  800]
loss: 2427.572306 [  192/  800]
loss: 2651.561934 [  352/  800]
loss: 2552.711327 [  512/  800]
loss: 2385.428237 [  672/  800]
Epoch complete - average loss: 2403.840784
Root MSE: 49.829295

Epoch 34/100
-------------------------------
loss: 1786.432617 [   32/  800]
loss: 2319.188477 [  192/  800]
loss: 2289.065674 [  352/  800]
loss: 2365.846405 [  512/  800]
loss: 2456.812047 [  672/  800]
Epoch complete - average loss: 2381.009785
Root MSE: 49.626731

Epoch 35/100
-------------------------------
loss: 2545.829834 [   32/  800]
loss: 2432.070516 [  192/  800]
loss: 2394.333085 [  352/  800]
loss: 2401.962784 [  512/  800]
loss: 2326.241595 [  672/  800]
Epoch complete - average loss: 2358.885322
Root MSE: 49.443105

Epoch 36/100
-------------------------------
loss: 2692.285645 [   32/  800]
loss: 2294.231567 [  192/  800]
loss: 2199.643100 [  352/  800]
loss: 2150.244408 [  512/  800]
loss: 2392.336530 [  672/  800]
Epoch complete - average loss: 2342.476899
Root MSE: 49.265887

Epoch 37/100
-------------------------------
loss: 3509.583252 [   32/  800]
loss: 2672.713806 [  192/  800]
loss: 2331.982932 [  352/  800]
loss: 2258.042923 [  512/  800]
loss: 2350.925665 [  672/  800]
Epoch complete - average loss: 2323.205283
Root MSE: 49.114603

Epoch 38/100
-------------------------------
loss: 1754.899170 [   32/  800]
loss: 2602.984182 [  192/  800]
loss: 2542.420826 [  352/  800]
loss: 2410.643917 [  512/  800]
loss: 2412.069996 [  672/  800]
Epoch complete - average loss: 2307.362043
Root MSE: 48.964555

Epoch 39/100
-------------------------------
loss: 2720.381592 [   32/  800]
loss: 2380.698954 [  192/  800]
loss: 2659.058716 [  352/  800]
loss: 2554.194298 [  512/  800]
loss: 2403.848394 [  672/  800]
Epoch complete - average loss: 2291.775542
Root MSE: 48.835828

Epoch 40/100
-------------------------------
loss: 2158.745361 [   32/  800]
loss: 1987.131246 [  192/  800]
loss: 2188.484453 [  352/  800]
loss: 2391.283623 [  512/  800]
loss: 2247.418166 [  672/  800]
Epoch complete - average loss: 2280.646475
Root MSE: 48.732849

Epoch 41/100
-------------------------------
loss: 3492.979980 [   32/  800]
loss: 2553.649028 [  192/  800]
loss: 2196.196444 [  352/  800]
loss: 2367.243050 [  512/  800]
loss: 2301.428304 [  672/  800]
Epoch complete - average loss: 2268.818501
Root MSE: 48.621063

Epoch 42/100
-------------------------------
loss: 2755.333496 [   32/  800]
loss: 2775.980815 [  192/  800]
loss: 2362.530207 [  352/  800]
loss: 2322.594009 [  512/  800]
loss: 2255.763062 [  672/  800]
Epoch complete - average loss: 2257.724282
Root MSE: 48.528350

Epoch 43/100
-------------------------------
loss: 2582.705078 [   32/  800]
loss: 2446.661784 [  192/  800]
loss: 2251.719749 [  352/  800]
loss: 2126.946793 [  512/  800]
loss: 2206.036022 [  672/  800]
Epoch complete - average loss: 2249.180652
Root MSE: 48.450720

Epoch 44/100
-------------------------------
loss: 1813.361694 [   32/  800]
loss: 2391.909587 [  192/  800]
loss: 2330.956410 [  352/  800]
loss: 2267.802040 [  512/  800]
loss: 2302.863148 [  672/  800]
Epoch complete - average loss: 2239.902554
Root MSE: 48.369830

Epoch 45/100
-------------------------------
loss: 2142.965332 [   32/  800]
loss: 2452.878418 [  192/  800]
loss: 2175.458862 [  352/  800]
loss: 2120.939285 [  512/  800]
loss: 2221.210775 [  672/  800]
Epoch complete - average loss: 2231.869326
Root MSE: 48.307679

Epoch 46/100
-------------------------------
loss: 1799.973022 [   32/  800]
loss: 2186.276143 [  192/  800]
loss: 2171.868086 [  352/  800]
loss: 2306.999985 [  512/  800]
loss: 2255.695728 [  672/  800]
Epoch complete - average loss: 2224.111365
Root MSE: 48.247138

Epoch 47/100
-------------------------------
loss: 1954.732422 [   32/  800]
loss: 2165.586446 [  192/  800]
loss: 2079.056674 [  352/  800]
loss: 2312.755547 [  512/  800]
loss: 2182.231823 [  672/  800]
Epoch complete - average loss: 2219.190122
Root MSE: 48.194604

Epoch 48/100
-------------------------------
loss: 2260.912842 [   32/  800]
loss: 1871.727743 [  192/  800]
loss: 1988.284113 [  352/  800]
loss: 2110.079887 [  512/  800]
loss: 2113.193493 [  672/  800]
Epoch complete - average loss: 2214.099575
Root MSE: 48.155458

Epoch 49/100
-------------------------------
loss: 3355.832031 [   32/  800]
loss: 2492.735372 [  192/  800]
loss: 2181.615001 [  352/  800]
loss: 2125.268219 [  512/  800]
loss: 2212.962158 [  672/  800]
Epoch complete - average loss: 2209.301885
Root MSE: 48.106140

Epoch 50/100
-------------------------------
loss: 1703.547729 [   32/  800]
loss: 2217.447266 [  192/  800]
loss: 2295.875089 [  352/  800]
loss: 2141.239731 [  512/  800]
loss: 2193.801903 [  672/  800]
Epoch complete - average loss: 2204.111099
Root MSE: 48.068497

Epoch 51/100
-------------------------------
loss: 3249.963867 [   32/  800]
loss: 2042.315531 [  192/  800]
loss: 2049.882269 [  352/  800]
loss: 2135.454338 [  512/  800]
loss: 2188.334525 [  672/  800]
Epoch complete - average loss: 2200.265400
Root MSE: 48.036688

Epoch 52/100
-------------------------------
loss: 2617.395996 [   32/  800]
loss: 2386.343262 [  192/  800]
loss: 2091.326982 [  352/  800]
loss: 2268.679214 [  512/  800]
loss: 2248.733736 [  672/  800]
Epoch complete - average loss: 2197.273701
Root MSE: 48.011468

Epoch 53/100
-------------------------------
loss: 1854.145996 [   32/  800]
loss: 2303.945353 [  192/  800]
loss: 2214.573864 [  352/  800]
loss: 2046.269547 [  512/  800]
loss: 2072.514474 [  672/  800]
Epoch complete - average loss: 2193.486631
Root MSE: 47.989118

Epoch 54/100
-------------------------------
loss: 1825.435059 [   32/  800]
loss: 2156.658834 [  192/  800]
loss: 2463.911111 [  352/  800]
loss: 2407.709785 [  512/  800]
loss: 2299.056420 [  672/  800]
Epoch complete - average loss: 2190.903931
Root MSE: 47.965354

Epoch 55/100
-------------------------------
loss: 1553.875244 [   32/  800]
loss: 2209.228780 [  192/  800]
loss: 1992.057950 [  352/  800]
loss: 1892.490334 [  512/  800]
loss: 2095.816133 [  672/  800]
Epoch complete - average loss: 2188.894038
Root MSE: 47.953161

Epoch 56/100
-------------------------------
loss: 1303.382080 [   32/  800]
loss: 1729.538350 [  192/  800]
loss: 2019.511741 [  352/  800]
loss: 2105.490936 [  512/  800]
loss: 2145.567197 [  672/  800]
Epoch complete - average loss: 2187.837227
Root MSE: 47.935269

Epoch 57/100
-------------------------------
loss: 2509.868164 [   32/  800]
loss: 2081.629476 [  192/  800]
loss: 2097.504583 [  352/  800]
loss: 2206.030983 [  512/  800]
loss: 2182.510556 [  672/  800]
Epoch complete - average loss: 2185.207090
Root MSE: 47.919412

Epoch 58/100
-------------------------------
loss: 1326.063965 [   32/  800]
loss: 1791.235168 [  192/  800]
loss: 2075.906527 [  352/  800]
loss: 2226.192924 [  512/  800]
loss: 2192.906093 [  672/  800]
Epoch complete - average loss: 2184.763369
Root MSE: 47.907501

Epoch 59/100
-------------------------------
loss: 3831.821289 [   32/  800]
loss: 2594.089864 [  192/  800]
loss: 2543.924217 [  352/  800]
loss: 2332.308983 [  512/  800]
loss: 2237.499140 [  672/  800]
Epoch complete - average loss: 2183.547563
Root MSE: 47.899396

Epoch 60/100
-------------------------------
loss: 3079.898438 [   32/  800]
loss: 2329.418559 [  192/  800]
loss: 2177.467618 [  352/  800]
loss: 2234.665825 [  512/  800]
loss: 2210.732352 [  672/  800]
Epoch complete - average loss: 2181.720049
Root MSE: 47.891276

Epoch 61/100
-------------------------------
loss: 3114.268066 [   32/  800]
loss: 2129.765971 [  192/  800]
loss: 2110.015980 [  352/  800]
loss: 2134.863304 [  512/  800]
loss: 2141.680391 [  672/  800]
Epoch complete - average loss: 2180.715845
Root MSE: 47.885585

Epoch 62/100
-------------------------------
loss: 1393.391724 [   32/  800]
loss: 2428.840108 [  192/  800]
loss: 2219.449796 [  352/  800]
loss: 2080.392570 [  512/  800]
loss: 2208.771444 [  672/  800]
Epoch complete - average loss: 2179.339058
Root MSE: 47.881332

Epoch 63/100
-------------------------------
loss: 2280.151611 [   32/  800]
loss: 2037.657756 [  192/  800]
loss: 2103.459473 [  352/  800]
loss: 2274.581604 [  512/  800]
loss: 2188.898060 [  672/  800]
Epoch complete - average loss: 2179.209912
Root MSE: 47.876346

Epoch 64/100
-------------------------------
loss: 1380.323486 [   32/  800]
loss: 1966.855957 [  192/  800]
loss: 1963.857389 [  352/  800]
loss: 2018.641747 [  512/  800]
loss: 2073.520932 [  672/  800]
Epoch complete - average loss: 2177.693120
Root MSE: 47.874217

Epoch 65/100
-------------------------------
loss: 2665.790771 [   32/  800]
loss: 2267.650635 [  192/  800]
loss: 2302.920588 [  352/  800]
loss: 2141.376564 [  512/  800]
loss: 2174.698963 [  672/  800]
Epoch complete - average loss: 2177.378860
Root MSE: 47.870593

Epoch 66/100
-------------------------------
loss: 2649.811279 [   32/  800]
loss: 2392.553731 [  192/  800]
loss: 2559.374290 [  352/  800]
loss: 2296.653244 [  512/  800]
loss: 2248.578218 [  672/  800]
Epoch complete - average loss: 2177.842798
Root MSE: 47.867411

Epoch 67/100
-------------------------------
loss: 2480.746582 [   32/  800]
loss: 2357.676819 [  192/  800]
loss: 2173.498702 [  352/  800]
loss: 2238.684044 [  512/  800]
loss: 2217.293521 [  672/  800]
Epoch complete - average loss: 2176.941177
Root MSE: 47.865702

Epoch 68/100
-------------------------------
loss: 1459.308960 [   32/  800]
loss: 2242.081604 [  192/  800]
loss: 2057.056796 [  352/  800]
loss: 2160.459534 [  512/  800]
loss: 2142.927234 [  672/  800]
Epoch complete - average loss: 2176.265449
Root MSE: 47.865316

Epoch 69/100
-------------------------------
loss: 1819.070312 [   32/  800]
loss: 1845.712992 [  192/  800]
loss: 1906.081221 [  352/  800]
loss: 2096.375626 [  512/  800]
loss: 2076.064645 [  672/  800]
Epoch complete - average loss: 2175.220903
Root MSE: 47.864617

Epoch 70/100
-------------------------------
loss: 1156.551880 [   32/  800]
loss: 2169.157878 [  192/  800]
loss: 2222.260398 [  352/  800]
loss: 2260.738930 [  512/  800]
loss: 2166.123186 [  672/  800]
Epoch complete - average loss: 2176.202959
Root MSE: 47.863247

Epoch 71/100
-------------------------------
loss: 1615.568604 [   32/  800]
loss: 2091.430623 [  192/  800]
loss: 2481.649270 [  352/  800]
loss: 2404.324486 [  512/  800]
loss: 2234.679350 [  672/  800]
Epoch complete - average loss: 2175.599438
Root MSE: 47.862660

Epoch 72/100
-------------------------------
loss: 1563.326172 [   32/  800]
loss: 2235.380432 [  192/  800]
loss: 2064.696245 [  352/  800]
loss: 2114.802109 [  512/  800]
loss: 2250.137230 [  672/  800]
Epoch complete - average loss: 2174.732187
Root MSE: 47.862702

Epoch 73/100
-------------------------------
loss: 2395.863525 [   32/  800]
loss: 2440.772115 [  192/  800]
loss: 2373.191084 [  352/  800]
loss: 2279.302277 [  512/  800]
loss: 2217.595244 [  672/  800]
Epoch complete - average loss: 2175.599165
Root MSE: 47.862620

Epoch 74/100
-------------------------------
loss: 2165.975342 [   32/  800]
loss: 1910.898092 [  192/  800]
loss: 2131.585494 [  352/  800]
loss: 2126.969673 [  512/  800]
loss: 2169.688093 [  672/  800]
Epoch complete - average loss: 2174.834678
Root MSE: 47.862667

Epoch 75/100
-------------------------------
loss: 3010.386719 [   32/  800]
loss: 2213.103455 [  192/  800]
loss: 2275.721879 [  352/  800]
loss: 2217.597366 [  512/  800]
loss: 2148.258527 [  672/  800]
Epoch complete - average loss: 2174.106230
Root MSE: 47.862821

Epoch 76/100
-------------------------------
loss: 1836.772583 [   32/  800]
loss: 2209.430440 [  192/  800]
loss: 2366.952348 [  352/  800]
loss: 2301.260818 [  512/  800]
loss: 2201.135966 [  672/  800]
Epoch complete - average loss: 2175.401404
Root MSE: 47.863278

Epoch 77/100
-------------------------------
loss: 1509.766113 [   32/  800]
loss: 2058.175863 [  192/  800]
loss: 2088.226285 [  352/  800]
loss: 2192.824341 [  512/  800]
loss: 2141.188918 [  672/  800]
Epoch complete - average loss: 2173.538799
Root MSE: 47.863284

Epoch 78/100
-------------------------------
loss: 1403.210815 [   32/  800]
loss: 1903.371053 [  192/  800]
loss: 2004.456377 [  352/  800]
loss: 2068.163841 [  512/  800]
loss: 2095.384097 [  672/  800]
Epoch complete - average loss: 2174.182046
Root MSE: 47.863573

Early stopping at epoch 78
Validation loss didn't improve for 5 epochs.
lowest validation loss: 2290.830409458705 in epoch 72
lowest training loss: 2173.538798828125 in epoch 76
Training and evaluating model: GRU hidden dimensions: 64, number of layers: 1 on dataset: Non-padding

Epoch 1/100
-------------------------------
loss: 3934.390869 [   32/  795]
loss: 4530.690999 [  192/  795]
loss: 5112.790261 [  352/  795]
loss: 5484.776886 [  512/  795]
loss: 5963.862723 [  672/  795]
/home/dorus/Documenten/UU/Blok 4/deep_learning/Deep-learning-assignment-1/.venv/lib/python3.12/site-packages/torch/nn/modules/loss.py:610: UserWarning: Using a target size (torch.Size([27, 1])) that is different to the input size (torch.Size([27])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.
  return F.mse_loss(input, target, reduction=self.reduction)
Epoch complete - average loss: 5854.711794
Root MSE: 64.996877

Epoch 2/100
-------------------------------
loss: 6718.826172 [   32/  795]
loss: 6523.707316 [  192/  795]
loss: 6210.177623 [  352/  795]
loss: 5756.630966 [  512/  795]
loss: 5588.080311 [  672/  795]
Epoch complete - average loss: 5635.877418
Root MSE: 63.550024

Epoch 3/100
-------------------------------
loss: 3910.944824 [   32/  795]
loss: 5496.507975 [  192/  795]
loss: 5485.289373 [  352/  795]
loss: 5772.239227 [  512/  795]
loss: 5660.426816 [  672/  795]
Epoch complete - average loss: 5397.121505
Root MSE: 61.928732

Epoch 4/100
-------------------------------
loss: 5365.736328 [   32/  795]
loss: 5356.322957 [  192/  795]
loss: 5215.093617 [  352/  795]
loss: 5341.822693 [  512/  795]
loss: 5006.237979 [  672/  795]
Epoch complete - average loss: 5172.574431
Root MSE: 60.609621

Epoch 5/100
-------------------------------
loss: 3345.902344 [   32/  795]
loss: 4843.416992 [  192/  795]
loss: 5198.744274 [  352/  795]
loss: 5046.293442 [  512/  795]
loss: 5076.615618 [  672/  795]
Epoch complete - average loss: 4980.031027
Root MSE: 59.370529

Epoch 6/100
-------------------------------
loss: 3790.496826 [   32/  795]
loss: 4855.792603 [  192/  795]
loss: 4781.920787 [  352/  795]
loss: 4846.479355 [  512/  795]
loss: 4737.285540 [  672/  795]
Epoch complete - average loss: 4803.579780
Root MSE: 58.219950

Epoch 7/100
-------------------------------
loss: 2657.734375 [   32/  795]
loss: 4464.605184 [  192/  795]
loss: 4694.918790 [  352/  795]
loss: 4755.869598 [  512/  795]
loss: 4568.686965 [  672/  795]
Epoch complete - average loss: 4628.403393
Root MSE: 56.947209

Epoch 8/100
-------------------------------
loss: 3343.882812 [   32/  795]
loss: 4347.623088 [  192/  795]
loss: 4470.692660 [  352/  795]
loss: 4409.230782 [  512/  795]
loss: 4439.498518 [  672/  795]
Epoch complete - average loss: 4441.580775
Root MSE: 55.622692

Epoch 9/100
-------------------------------
loss: 4115.130859 [   32/  795]
loss: 4555.641602 [  192/  795]
loss: 4257.756592 [  352/  795]
loss: 4264.975266 [  512/  795]
loss: 4339.876430 [  672/  795]
Epoch complete - average loss: 4267.735097
Root MSE: 54.527855

Epoch 10/100
-------------------------------
loss: 2413.273682 [   32/  795]
loss: 3391.521891 [  192/  795]
loss: 4161.899969 [  352/  795]
loss: 4015.408737 [  512/  795]
loss: 3984.997814 [  672/  795]
Epoch complete - average loss: 4121.575748
Root MSE: 53.559999

Epoch 11/100
-------------------------------
loss: 1882.074951 [   32/  795]
loss: 3583.208293 [  192/  795]
loss: 4194.401989 [  352/  795]
loss: 3926.004822 [  512/  795]
loss: 3901.361328 [  672/  795]
Epoch complete - average loss: 3991.586861
Root MSE: 52.659545

Epoch 12/100
-------------------------------
loss: 3417.442627 [   32/  795]
loss: 3096.396769 [  192/  795]
loss: 3649.864014 [  352/  795]
loss: 3712.355728 [  512/  795]
loss: 3717.405785 [  672/  795]
Epoch complete - average loss: 3867.097991
Root MSE: 51.744464

Epoch 13/100
-------------------------------
loss: 3576.701904 [   32/  795]
loss: 3333.298584 [  192/  795]
loss: 3540.613503 [  352/  795]
loss: 3847.708694 [  512/  795]
loss: 3903.946824 [  672/  795]
Epoch complete - average loss: 3736.510039
Root MSE: 50.754914

Epoch 14/100
-------------------------------
loss: 4642.140137 [   32/  795]
loss: 3063.616292 [  192/  795]
loss: 3253.851063 [  352/  795]
loss: 3262.044640 [  512/  795]
loss: 3511.527361 [  672/  795]
Epoch complete - average loss: 3605.160204
Root MSE: 49.903216

Epoch 15/100
-------------------------------
loss: 3433.453125 [   32/  795]
loss: 3421.137410 [  192/  795]
loss: 3297.805475 [  352/  795]
loss: 3594.340309 [  512/  795]
loss: 3604.758853 [  672/  795]
Epoch complete - average loss: 3495.293892
Root MSE: 49.133213

Epoch 16/100
-------------------------------
loss: 2245.021240 [   32/  795]
loss: 3501.486287 [  192/  795]
loss: 3368.221502 [  352/  795]
loss: 3150.370247 [  512/  795]
loss: 3413.891759 [  672/  795]
Epoch complete - average loss: 3394.117935
Root MSE: 48.453139

Epoch 17/100
-------------------------------
loss: 5978.200684 [   32/  795]
loss: 4373.759196 [  192/  795]
loss: 3684.821167 [  352/  795]
loss: 3608.050850 [  512/  795]
loss: 3375.474016 [  672/  795]
Epoch complete - average loss: 3303.556417
Root MSE: 47.804091

Epoch 18/100
-------------------------------
loss: 2211.996338 [   32/  795]
loss: 3151.780070 [  192/  795]
loss: 3119.920077 [  352/  795]
loss: 3120.420776 [  512/  795]
loss: 3158.448975 [  672/  795]
Epoch complete - average loss: 3214.165933
Root MSE: 47.188292

Epoch 19/100
-------------------------------
loss: 601.149414 [   32/  795]
loss: 2651.353394 [  192/  795]
loss: 3089.596480 [  352/  795]
loss: 3265.914017 [  512/  795]
loss: 3211.048224 [  672/  795]
Epoch complete - average loss: 3129.656763
Root MSE: 46.614042

Epoch 20/100
-------------------------------
loss: 3762.110840 [   32/  795]
loss: 2557.260274 [  192/  795]
loss: 3021.530174 [  352/  795]
loss: 3035.224960 [  512/  795]
loss: 3047.662371 [  672/  795]
Epoch complete - average loss: 3053.244301
Root MSE: 46.119101

Epoch 21/100
-------------------------------
loss: 1671.686157 [   32/  795]
loss: 2545.193766 [  192/  795]
loss: 2892.857222 [  352/  795]
loss: 2885.501907 [  512/  795]
loss: 2958.947114 [  672/  795]
Epoch complete - average loss: 2984.045154
Root MSE: 45.670667

Epoch 22/100
-------------------------------
loss: 2875.577393 [   32/  795]
loss: 3576.089803 [  192/  795]
loss: 3093.251676 [  352/  795]
loss: 2760.916786 [  512/  795]
loss: 2887.547206 [  672/  795]
Epoch complete - average loss: 2921.727238
Root MSE: 45.265217

Epoch 23/100
-------------------------------
loss: 4293.706543 [   32/  795]
loss: 2429.797485 [  192/  795]
loss: 2890.688166 [  352/  795]
loss: 2689.584892 [  512/  795]
loss: 2682.652280 [  672/  795]
Epoch complete - average loss: 2863.939644
Root MSE: 44.897883

Epoch 24/100
-------------------------------
loss: 2472.302734 [   32/  795]
